# RealEstateAggregator ‚Äì Architektura syst√©mu

> **Verze:** Session 19 (27. √∫nora 2026)
> **√öƒçel:** Zevrubn√Ω technick√Ω popis cel√©ho syst√©mu ‚Äì stack, datov√Ω tok, RAG pipeline do nejmen≈°√≠ho
> detailu, AI funkce, Vision OCR, DB sch√©ma, prostorov√© filtry, API reference.

---

## Obsah

1. [Executive Summary](#1-executive-summary)
2. [Technology Stack](#2-technology-stack)
3. [Syst√©mov√° architektura (Docker Compose)](#3-syst√©mov√°-architektura-docker-compose)
4. [Scraping pipeline](#4-scraping-pipeline)
   - 4.1 [Tok dat end-to-end](#41-tok-dat-end-to-end)
   - 4.2 [Upsert & deduplication](#42-upsert--deduplication)
   - 4.3 [FilterManager pipeline](#43-filtermanager-pipeline)
   - 4.4 [APScheduler (napl√°novan√Ω bƒõh)](#44-apscheduler-napl√°novan√Ω-bƒõh)
5. [RAG ‚Äì Retrieval-Augmented Generation](#5-rag--retrieval-augmented-generation)
   - 5.1 [P≈ôehled t≈ô√≠ pipeline](#51-p≈ôehled-t≈ô√≠-pipeline)
   - 5.2 [Ingestion pipeline ‚Äì detail](#52-ingestion-pipeline--detail)
   - 5.3 [Retrieval pipeline ‚Äì detail](#53-retrieval-pipeline--detail)
   - 5.4 [Generation pipeline ‚Äì detail](#54-generation-pipeline--detail)
   - 5.5 [Pln√Ω sekvenƒçn√≠ diagram RAG cyklu](#55-pln√Ω-sekvenƒçn√≠-diagram-rag-cyklu)
   - 5.6 [Vektorov√© indexy a SQL](#56-vektorov√©-indexy-a-sql)
   - 5.7 [Cosine similarity ‚Äì matematika](#57-cosine-similarity--matematika)
   - 5.8 [Fallback strategie](#58-fallback-strategie)
6. [Ollama Vision ‚Äì klasifikace fotek](#6-ollama-vision--klasifikace-fotek)
   - 6.1 [Dvoupr≈Øchodov√° klasifikace](#61-dvoupr≈Øchodov√°-klasifikace)
   - 6.2 [Klasifikace fotek z prohl√≠dky](#62-klasifikace-fotek-z-prohl√≠dky)
   - 6.3 [Alt text (WCAG 2.2 AA)](#63-alt-text-wcag-22-aa)
7. [Ollama Text ‚Äì AI funkce](#7-ollama-text--ai-funkce)
   - 7.1 [Smart Tags](#71-smart-tags)
   - 7.2 [Normalizace dat](#72-normalizace-dat)
   - 7.3 [Cenov√Ω sign√°l](#73-cenov√Ω-sign√°l)
   - 7.4 [Detekce duplik√°t≈Ø](#74-detekce-duplik√°t≈Ø)
   - 7.5 [Robustn√≠ JSON parsov√°n√≠](#75-robustn√≠-json-parsov√°n√≠)
8. [KN OCR ‚Äì Screenshot z katastru](#8-kn-ocr--screenshot-z-katastru)
9. [Prostorov√© vyhled√°v√°n√≠ (PostGIS)](#9-prostorov√©-vyhled√°v√°n√≠-postgis)
   - 9.1 [Koridorov√© filtrov√°n√≠](#91-koridorov√©-filtrov√°n√≠)
   - 9.2 [Geocoding pipeline](#92-geocoding-pipeline)
10. [DB sch√©ma (ERD)](#10-db-sch√©ma-erd)
11. [API endpoint reference](#11-api-endpoint-reference)
12. [MCP Tools ‚Äì Claude Desktop integrace](#12-mcp-tools--claude-desktop-integrace)
13. [Export pipeline (Google Drive / OneDrive)](#13-export-pipeline-google-drive--onedrive)
14. [Konfigurace a secrets](#14-konfigurace-a-secrets)
15. [Monitoring a logging](#15-monitoring-a-logging)
16. [V√Ωkonnostn√≠ tipy & indexov√° strategie](#16-v√Ωkonnostn√≠-tipy--indexov√°-strategie)

---

## 1. Executive Summary

**RealEstateAggregator** je plnohodnotn√° ƒçesk√° realitn√≠ agregaƒçn√≠ platforma druh√© generace. Kontinu√°lnƒõ stahuje inzer√°ty z **13 zdroj≈Ø**, ukl√°d√° je do PostgreSQL s PostGIS a pgvector a nab√≠z√≠ nad nimi celou sadu AI slu≈æeb:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     WHAT THIS SYSTEM CAN DO                             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Agregace inzer√°t≈Ø (13 zdroj≈Ø)  ‚îÇ Python AsyncIO + httpx/BS4, upsert    ‚îÇ
‚îÇ Plnotextov√© vyhled√°v√°n√≠        ‚îÇ PostgreSQL tsvector + GIN index        ‚îÇ
‚îÇ S√©mantick√© vyhled√°v√°n√≠         ‚îÇ pgvector HNSW (768-dim), nomic-embed  ‚îÇ
‚îÇ RAG chat nad inzer√°ty          ‚îÇ pgvector IVFFlat + qwen2.5:14b        ‚îÇ
‚îÇ Klasifikace fotek (Vision)     ‚îÇ llama3.2-vision:11b (2 pr≈Øchody)      ‚îÇ
‚îÇ Smart tagy + normalizace + cena‚îÇ llama3.2 text, strukturovan√© prompty  ‚îÇ
‚îÇ KN OCR ze screenshotu          ‚îÇ llama3.2-vision, Ctrl+V clipboard     ‚îÇ
‚îÇ Prostorov√© filtrov√°n√≠          ‚îÇ PostGIS ST_Buffer + OSRM routing       ‚îÇ
‚îÇ Katastr nemovitost√≠            ‚îÇ R√öIAN / ƒå√öZK REST + OCR Vision        ‚îÇ
‚îÇ MCP integrace (Claude Desktop) ‚îÇ Python FastAPI MCP SSE server          ‚îÇ
‚îÇ Export pro AI anal√Ωzu          ‚îÇ Google Drive / OneDrive + ≈°ablony .md ‚îÇ
‚îÇ Geocoding 97 % pokryt√≠         ‚îÇ Nominatim OSM (1 366 / 1 416 GPS bod≈Ø)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Aktu√°ln√≠ stav DB:** 1 416 inzer√°t≈Ø, 13 zdroj≈Ø, 97 % geoc√≥dov√°no.

---

## 2. Technology Stack

### 2.1 Backend

| Technologie | Verze | Role |
|---|---|---|
| .NET / ASP.NET Core | **10.0** | ASP.NET Minimal API, Blazor Server |
| Entity Framework Core | 10.x | ORM, migrations, LINQ queries |
| Npgsql.EntityFrameworkCore.PostgreSQL | 10.x | PostgreSQL provider + NTS geometry |
| Pgvector.EntityFrameworkCore | latest | `Vector(dim)` typ pro pgvector |
| NetTopologySuite | 2.x | `Geometry`, `Point`, `Polygon` v C# |
| Serilog.AspNetCore | 9.x | Strukturovan√© logov√°n√≠ (console/JSON) |

### 2.2 Frontend

| Technologie | Verze | Role |
|---|---|---|
| Blazor Server | .NET 10 | Interaktivn√≠ UI p≈ôes SignalR WebSocket |
| MudBlazor | **9.x** | UI komponenty (karty, filtry, dialogy, carousel) |
| Leaflet.js | 1.x | Interaktivn√≠ mapa (markery + koridory) |
| Vanilla JS interop | ‚Äì | `kn-ocr.js` (clipboard paste, drag&drop, FileReader) |

### 2.3 Datab√°ze a roz≈°√≠≈ôen√≠

| Technologie | Verze | Role |
|---|---|---|
| PostgreSQL | **15** | Prim√°rn√≠ datab√°ze, schema `re_realestate` |
| PostGIS | **3.4** | `geometry`, `GIST` index, `ST_Buffer`, `ST_Intersects` |
| pgvector | **0.7+** | `vector(768)`, `HNSW` a `IVFFlat` indexy |
| `uuid-ossp` | built-in | `gen_random_uuid()` |

### 2.4 AI / LLM modely (Ollama lok√°lnƒõ)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Model                    ‚îÇ Typ         ‚îÇ Dim    ‚îÇ √öƒçel                              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ nomic-embed-text         ‚îÇ Embedding   ‚îÇ 768    ‚îÇ RAG anal√Ωzy ‚Äì listing_analyses    ‚îÇ
‚îÇ qwen2.5:14b              ‚îÇ Chat LLM    ‚îÇ ‚Äì      ‚îÇ RAG ‚Äì generov√°n√≠ odpovƒõd√≠         ‚îÇ
‚îÇ llama3.2-vision:11b      ‚îÇ Vision LLM  ‚îÇ ‚Äì      ‚îÇ Klasifikace fotek, KN OCR         ‚îÇ
‚îÇ llama3.2 (text)          ‚îÇ Chat LLM    ‚îÇ ‚Äì      ‚îÇ Smart tags, normalizace, cena      ‚îÇ
‚îÇ text-embedding-3-small*  ‚îÇ Embedding   ‚îÇ 1 536  ‚îÇ *Legacy: description_embedding    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
* OpenAI ‚Äì pou≈æ√≠v√°n historicky pro listings.description_embedding (HNSW index).
  Nov√Ω RAG stack bƒõ≈æ√≠ 100 % lok√°lnƒõ na Ollama (nomic-embed-text, 768 dim).
```

### 2.5 Infrastructure & External

| Technologie | √öƒçel |
|---|---|
| Docker Compose | Orchestrace 5 slu≈æeb + pgAdmin (profile: tools) |
| Colima (ARM64) | macOS Docker runtime, native ARM64, bez Rosetta |
| OSRM | Open-source routing (koridorov√Ω buffer) |
| Nominatim (OSM) | Geocoding s rate-limitem 1,1 s/req |
| R√öIAN / ƒå√öZK | Katastr√°ln√≠ REST API + OCR Vision fallback |
| APScheduler (Python) | Cron: dennƒõ 03:00 + t√Ωdnƒõ nedƒõle 02:00 |
| Google Drive / OneDrive | Cloud storage pro AI export bal√≠ƒçky |

---

## 3. Syst√©mov√° architektura (Docker Compose)

```mermaid
graph TB
    subgraph USER["üë§ U≈æivatel"]
        BROWSER["Prohl√≠≈æeƒç\nhttp://localhost:5002"]
        CLAUDE["Claude Desktop\n(MCP client)"]
    end

    subgraph DOCKER["üê≥ Docker Compose ¬∑ realestate-network"]
        direction TB
        APP["realestate-app\nBlazor Server\n:5002 ‚Üí :8080\n.NET 10"]
        API["realestate-api\nASP.NET Core Minimal API\n:5001 ‚Üí :8080\n.NET 10"]
        SCRAPER["realestate-scraper\nPython FastAPI\n:8001\nAsyncIO + httpx"]
        DB["realestate-db\nPostgreSQL 15\nPostGIS 3.4 + pgvector\n:5432"]
        MCP_SVC["realestate-mcp\nPython FastAPI MCP\n:8002 SSE"]
        PGADMIN["pgAdmin 4\n:5050\n(profile: tools)"]
    end

    subgraph EXT["üåê External services"]
        OLLAMA["Ollama :11434\nnomic-embed-text\nqwen2.5:14b\nllama3.2-vision:11b\nllama3.2"]
        OSRM["OSRM router\nproject-osrm.org"]
        NOM["Nominatim OSM\nopenstreetmap.org"]
        RUIAN["R√öIAN / ƒå√öZK\ncuzk.cz REST"]
        GDRIVE["Google Drive API"]
        ONEDRIVE["Microsoft OneDrive"]
        SITES["13 ƒçesk√Ωch realitn√≠ch web≈Ø"]
    end

    subgraph VOL["üíæ Docker Volumes"]
        PG_VOL["postgres_data\nPostgreSQL WAL + data"]
        UP_VOL["uploads_data\n/app/wwwroot/uploads\nfotky + exporty"]
        SEC_VOL["./secrets\nGoogle Drive credentials"]
    end

    BROWSER -->|HTTP| APP
    APP -->|"HTTP REST ¬∑ ApiBaseUrl\nhttp://realestate-api:8080"| API
    CLAUDE -->|"MCP SSE :8002\ntool calls"| MCP_SVC
    MCP_SVC -->|HTTP REST| API
    MCP_SVC -->|"HTTP :11434\nembedding pro save_analysis"| OLLAMA

    API -->|"EF Core / Npgsql\nTCP :5432"| DB
    SCRAPER -->|"asyncpg\ndirect SQL"| DB
    API -->|"HTTP :8001\nPOST /v1/scrape/run"| SCRAPER
    API -->|"HTTP :11434\nembed + chat + vision"| OLLAMA
    API -->|HTTPS| GDRIVE
    API -->|HTTPS| ONEDRIVE
    API -->|HTTPS| RUIAN
    API -->|HTTPS| OSRM
    API -->|HTTPS| NOM

    SCRAPER -->|HTTP scraping| SITES

    DB --- PG_VOL
    API --- UP_VOL
    API --- SEC_VOL
    PGADMIN -->|"TCP :5432"| DB
```

### Vnit≈ôn√≠ s√≠≈•ov√° komunikace

| Caller | Callee | Adresa (Docker-intern) |
|---|---|---|
| `app` | `api` | `http://realestate-api:8080` |
| `api` | `scraper` | `http://realestate-scraper:8001` |
| `api` / `mcp` | Ollama | `http://host.docker.internal:11434` |
| `api` / `scraper` | postgres | `realestate-db:5432` |

---

## 4. Scraping pipeline

### 4.1 Tok dat end-to-end

```mermaid
flowchart TD
    subgraph TRIGGER["Spu≈°tƒõn√≠"]
        UI_TRIG["Blazor UI\n/admin/scraping\nPOST /api/scraping/trigger\n+ X-Api-Key header"]
        SCHED["APScheduler\ndennƒõ 03:00\nnedƒõlnƒõ 02:00 (full_rescan)"]
    end

    subgraph APIGATE["ASP.NET Core API ‚Äì br√°na"]
        APIMW["API Key Middleware\novƒõ≈ô X-Api-Key"]
        JOB_CRE["Vytvo≈ô scrape_jobs z√°znam\nstatus = Queued"]
        FWD["Forward request\nPOST :8001/v1/scrape/run\n{source_codes, full_rescan}"]
    end

    subgraph PYTHON["Python Scraper :8001"]
        RUNNER["runner.py\nAsyncIO orchestr√°tor\nparaleln√≠ per-scraper coroutines"]

        subgraph SCRAPER_CLASS["Scraper class (√ó13)"]
            LP["_parse_list_page(html)\n‚Üí List[dict] (z√°kladn√≠ data)"]
            DP["_parse_detail_page(html, item)\n‚Üí dict (kompletn√≠ data)"]
            RETRY["@http_retry (tenacity)\n3√ó retry, exponential backoff"]
        end

        FILTER["FilterManager\ngeo + kvalita + cenov√Ω limit"]
        DB_PY["database.py\nupsert_listing()\n_upsert_photos() max 20/inzer√°t"]
        DEACT["deactivate_unseen_listings()\ntoliko p≈ôi full_rescan=true"]
    end

    subgraph PG["PostgreSQL ¬∑ re_realestate"]
        L_TBL["listings\nINSERT (new) / UPDATE (existing)"]
        P_TBL["listing_photos\nDELETE + INSERT (atomic tx)"]
        SR_TBL["scrape_runs\nstatistika bƒõhu"]
        SJ_TBL["scrape_jobs\nprogress 0-100"]
        TRIG_GEO["TRIGGER: sync_location_point\nST_SetSRID(ST_MakePoint(lng,lat),4326)\n‚Üí location_point geometry"]
    end

    GEOCODE["Background: bulk-geocode\nPOST /api/spatial/bulk-geocode\nNominatim 1.1s / req"]

    UI_TRIG -->|"authenticated"| APIMW
    SCHED --> RUNNER
    APIMW --> JOB_CRE --> FWD --> RUNNER
    RUNNER --> SCRAPER_CLASS
    LP --> DP --> RETRY
    RETRY --> FILTER --> DB_PY
    DB_PY --> L_TBL
    DB_PY --> P_TBL
    DB_PY --> SR_TBL
    DB_PY --> DEACT
    FWD --> SJ_TBL
    L_TBL -->|"lat/lng zaps√°no"| TRIG_GEO
    L_TBL -.->|"chybƒõj√≠c√≠ GPS"| GEOCODE
    GEOCODE -->|"UPDATE lat/lng"| L_TBL
```

### 4.2 Upsert & deduplication

Kl√≠ƒçem z≈Øst√°v√° kompozitn√≠ dvojice `(source_id, external_id)`. Scraper nikdy nevkl√°d√° duplicity ‚Äì m√≠sto toho p≈ôepisuje data existuj√≠c√≠ho z√°znamu a aktualizuje `last_seen_at`.

```python
# database.py ‚Äì zjednodu≈°en√Ω pseudok√≥d
existing = await conn.fetchrow(
    '''SELECT id FROM re_realestate.listings
       WHERE source_id = $1 AND external_id = $2''',
    source_id, external_id
)

if existing:
    # UPDATE ‚Äì zachov√°me first_seen_at, p≈ôep√≠≈°eme ostatn√≠
    await conn.execute(
        "UPDATE re_realestate.listings SET title=$1, price=$2, ..., last_seen_at=now() WHERE id=$3",
        title, price, existing["id"]
    )
else:
    # INSERT ‚Äì nov√Ω inzer√°t
    listing_id = uuid4()
    await conn.execute(
        "INSERT INTO re_realestate.listings (id, source_id, external_id, ..., first_seen_at, last_seen_at)"
        " VALUES ($1,$2,$3,...,now(),now())",
        listing_id, source_id, external_id
    )

# Fotky: transakce DELETE + INSERT (atomick√° p≈ôestavba)
async with conn.transaction():
    await conn.execute(
        "DELETE FROM re_realestate.listing_photos WHERE listing_id=$1", listing_id
    )
    for idx, url in enumerate(photo_urls[:20]):
        await conn.execute("INSERT INTO re_realestate.listing_photos ...")
```

### 4.3 FilterManager pipeline

Ka≈æd√Ω raw inzer√°t projde t≈ôemi s√≠ty. Po≈ôad√≠ je d≈Øle≈æit√© ‚Äì geo-sito je nejrychlej≈°√≠ a zfiltruje nejv√≠ce.

```mermaid
flowchart LR
    RAW["üìÑ Raw inzer√°t\nlocation_text, price, title"] --> G

    G{"üó∫Ô∏è Geo filtr\nJe v povolen√© oblasti?\nJMK ¬∑ Jihoƒçesk√Ω ¬∑ ‚Ä¶"}
    G -->|"PASS"| Q
    G -->|"REJECT"| SKIP["zahozen\ngeo_filtered counter"]

    Q{"üìã Kvalita\ntitle != empty\ndescription != empty\nprice > 0"}
    Q -->|"PASS"| P
    Q -->|"REJECT"| SKIP

    P{"üí∞ Cenov√Ω limit\nHouse: max 10 M Kƒç\nLand: max 5 M Kƒç\n-1 = p≈ôeskoƒçit limit"}
    P -->|"PASS"| UPSERT["upsert_listing()"]
    P -->|"REJECT"| SKIP
```

### 4.4 APScheduler (napl√°novan√Ω bƒõh)

```python
# scraper/api/main.py
scheduler = AsyncIOScheduler(timezone="Europe/Prague")

# Denn√≠ incremental: rychl√Ω pr≈Øchod nov√Ωch inzer√°t≈Ø
scheduler.add_job(daily_scrape,  "cron", hour=3, minute=0,
                  id="daily_scrape",  args=[False])   # full_rescan=False

# T√Ωdenn√≠ full rescan: deaktivace zanikl√Ωch inzer√°t≈Ø
scheduler.add_job(weekly_rescan, "cron", day_of_week="sun", hour=2,
                  id="weekly_rescan", args=[True])    # full_rescan=True
```

Ruƒçn√≠ ovl√°d√°n√≠ p≈ôes endpoint `/v1/schedule/trigger-now?jobId=daily_scrape`.

---

## 5. RAG ‚Äì Retrieval-Augmented Generation

RAG syst√©m umo≈æ≈àuje **p≈ôirozenojazyƒçn√Ω chat nad ulo≈æen√Ωmi anal√Ωzami** konkr√©tn√≠ho inzer√°tu (nebo cross-listing vyhled√°v√°n√≠). Skl√°d√° se z p≈ôesnƒõ t≈ô√≠ pipeline, kter√© na sebe navazuj√≠.

### 5.1 P≈ôehled t≈ô√≠ pipeline

```mermaid
graph LR
    subgraph ING["‚ë† Ingestion Pipeline"]
        direction TB
        TXT["BuildListingText()\nStrukturovan√Ω text\n(max 8 000 znak≈Ø)"]
        TXT --> TRUNC["Truncate to 8 000 chars\nokno modelu nomic-embed-text"]
        TRUNC --> EMBED_ING["POST /api/embed\nnomic-embed-text\n768-dim float[]"]
        EMBED_ING --> STORE["INSERT listing_analyses\nembedding VECTOR(768)\nIVFFlat index"]
    end

    subgraph RET["‚ë° Retrieval Pipeline"]
        direction TB
        Q["Dotaz u≈æivatele\nstring question"]
        Q --> EMBED_Q["POST /api/embed\nnomic-embed-text\n768-dim queryVector"]
        EMBED_Q --> ANN["pgvector ANN\nORDER BY embedding <-> queryVec\nLIMIT topK  (IVFFlat approx.)"]
        ANN --> RERANK["In-memory exact rerank\nCosineSimilarity(chunk, query)\nsort DESC"]
        RERANK --> TOPK["Top-K chunks\n[content, score, title, source]"]
    end

    subgraph GEN["‚ë¢ Generation Pipeline"]
        direction TB
        CTX["BuildUserMessage()\nInzer√°t info + Top-K chunks\n+ ot√°zka"]
        SYS["BuildSystemPrompt()\nRole: CZ realitn√≠ expert"]
        CTX --> LLM["POST /api/chat\nqwen2.5:14b\nstream: false"]
        SYS --> LLM
        LLM --> ANS["AskResponseDto\nanswer + chunks + hasEmbeddings"]
    end

    STORE -.->|"ulo≈æen√© chunky"| ANN
    TOPK --> CTX
```

### 5.2 Ingestion pipeline ‚Äì detail

#### Kde vznikaj√≠ anal√Ωzy (t≈ôi zdroje)

| Source tag | Zp≈Øsob vzniku | Obsah |
|---|---|---|
| `"auto"` | `POST /api/rag/embed/{id}` nebo bulk-embed | Strukturovan√Ω text z `BuildListingText()` |
| `"claude"` | MCP `save_analysis` tool (Claude Desktop) | Libovoln√Ω text ‚Äì v√Ωsledek AI anal√Ωzy |
| `"user"` | UI tlaƒç√≠tko ‚ÄûUlo≈æit pozn√°mku" | U≈æivatelovy manu√°ln√≠ pozn√°mky |

#### `BuildListingText()` ‚Äì ≈°ablona

```
# {Title}
Typ: {PropertyType} | Nab√≠dka: {OfferType}
Cena: {Price} Kƒç
Lokalita: {LocationText}
Obec: {Municipality} | Okres: {District}
Dispozice: {Disposition} | Plocha zastavƒõn√°: {AreaBuiltUp} m¬≤ | Plocha pozemku: {AreaLand} m¬≤
Stav: {Condition} | Konstrukce: {ConstructionType}

## Popis
{Description}
```

- Truncace na **8 000 znak≈Ø** p≈ôed embeddingem (okno `nomic-embed-text`)
- Idempotence: `BulkEmbedDescriptionsAsync` p≈ôeskakuje inzer√°ty, kter√© ji≈æ maj√≠ `source="auto"` anal√Ωzu

#### Tok embedding requestu

```mermaid
sequenceDiagram
    participant RS as RagService.cs
    participant OE as OllamaEmbeddingService.cs
    participant OL as Ollama :11434
    participant DB as PostgreSQL

    RS->>OE: GetEmbeddingAsync(text[..8000])
    OE->>OL: POST /api/embed\n{"model":"nomic-embed-text","input":"..."}
    OL-->>OE: {"embeddings":[[0.12,-0.45,...]]}  float[768]
    OE-->>RS: float[] embedding

    RS->>DB: INSERT INTO listing_analyses\n(id, listing_id, content, source, embedding, created_at)
    DB-->>RS: OK  ListingAnalysisDto
```

### 5.3 Retrieval pipeline ‚Äì detail

#### `FindSimilarAsync()` ‚Äì dvƒõ varianty

```sql
-- Listing-specifick√© vyhled√°v√°n√≠ (pro AskListingAsync)
SELECT id, listing_id, content, title, source, embedding, created_at
FROM   re_realestate.listing_analyses
WHERE  listing_id = :listingId
  AND  embedding IS NOT NULL
ORDER  BY embedding <-> :queryVector   -- L2 distance (pgvector oper√°tor)
LIMIT  :topK;

-- Cross-listing vyhled√°v√°n√≠ (pro AskGeneralAsync)
SELECT id, listing_id, content, title, source, embedding, created_at
FROM   re_realestate.listing_analyses
WHERE  embedding IS NOT NULL
ORDER  BY embedding <-> :queryVector
LIMIT  :topK;
```

#### ANN ‚Üí p≈ôesn√Ω reranking

pgvector oper√°tor `<->` prov√°d√≠ **ANN** (Approximate Nearest Neighbor) p≈ôes IVFFlat index ‚Äì rychl√©, ale p≈ôibli≈æn√©. V√Ωsledky se pak p≈ôe≈ôad√≠ **p≈ôesnou cosine similarity** v pamƒõti:

```mermaid
flowchart LR
    ANN["pgvector IVFFlat ANN\nL2 distance ‚Äì p≈ôibli≈æn√©\ntop-K kandid√°ti"] --> EXACT["In-memory exact rerank\nCosineSimilarity(chunk.embedding, queryEmbedding)\nsort DESC by similarity"]
    EXACT --> OUT["V√Ωsledky se≈ôazen√©\np≈ôesn√Ωmi cosine sk√≥ry\n0.0 ‚Äì 1.0"]
```

### 5.4 Generation pipeline ‚Äì detail

#### System prompt (invariantn√≠)

```
Jsi AI asistent pom√°haj√≠c√≠ s anal√Ωzou nemovitost√≠ v ƒåesk√© republice.
Odpov√≠d√°≈° v ƒçe≈°tinƒõ. Vych√°z√≠≈° v√Ωhradnƒõ z poskytnut√©ho kontextu (anal√Ωz inzer√°t≈Ø).
Pokud kontext neobsahuje dostateƒçn√© informace, ≈ôekni to otev≈ôenƒõ.
Buƒè konkr√©tn√≠, vƒõcn√Ω a struƒçn√Ω.
P≈ôi odkazov√°n√≠ na zdroje uveƒè jejich po≈ôad√≠ [1], [2], atd.
```

#### User message ‚Äì struktura

```markdown
## Inzer√°t
{Title} | {LocationText} | {Price} Kƒç | {PropertyType} {OfferType}

## Ulo≈æen√© anal√Ωzy (kontext)

### Anal√Ωza [1]  (score: 0.87)
{chunk_1_content}

### Anal√Ωza [2]  (score: 0.74)
{chunk_2_content}

...

## Dotaz
{question}
```

#### `AskResponseDto` ‚Äì v√Ωstup endpointu

```csharp
record AskResponseDto(
    string           Answer,         // odpovƒõƒè LLM v ƒçe≈°tinƒõ
    List<AnalysisChunkDto> Chunks,   // top-K chunks (ContentExcerpt max 300 znak≈Ø + score)
    bool             HasEmbeddings   // false = fallback bez vektor≈Ø byl pou≈æit
);
```

### 5.5 Pln√Ω sekvenƒçn√≠ diagram RAG cyklu

```mermaid
sequenceDiagram
    actor User
    participant UI  as Blazor UI
    participant API as ASP.NET Core API
    participant RS  as RagService
    participant OE  as OllamaEmbeddingService
    participant OL  as Ollama :11434
    participant DB  as PostgreSQL (pgvector)

    User->>UI: "M√° tento d≈Øm vlhk√Ω sklep?"
    UI->>API: POST /api/rag/ask-listing/{id}\n{"question":"...","topK":5}

    API->>RS: AskListingAsync(listingId, question, topK=5)

    Note over RS,OE: RETRIEVAL PHASE
    RS->>OE: GetEmbeddingAsync(question)
    OE->>OL: POST /api/embed\n{"model":"nomic-embed-text","input":"M√° tento d≈Øm vlhk√Ω sklep?"}
    OL-->>OE: {"embeddings":[[0.12,-0.45,...768 float≈Ø...]]}
    OE-->>RS: float[768] queryVector

    RS->>DB: SELECT * FROM listing_analyses\nWHERE listing_id={id} AND embedding IS NOT NULL\nORDER BY embedding <-> queryVec LIMIT 5
    DB-->>RS: List<ListingAnalysis>  (IVFFlat ANN v√Ωsledky)

    Note over RS: In-memory exact rerank\nCosineSimilarity(chunk.Embedding, queryVector)\nsort DESC ‚Üí true top-5

    Note over RS,DB: CONTEXT LOAD PHASE
    RS->>DB: SELECT title, location_text, price, property_type FROM listings WHERE id={id}
    DB-->>RS: Listing entity

    Note over RS,OL: GENERATION PHASE
    RS->>RS: BuildSystemPrompt() ‚Üí konstantn√≠ CZ instrukce
    RS->>RS: BuildUserMessage(question, listing, sortedChunks)

    RS->>OE: ChatAsync(systemPrompt, userMessage)
    OE->>OL: POST /api/chat\n{"model":"qwen2.5:14b","stream":false,\n"messages":[{"role":"system",...},{"role":"user",...}]}
    OL-->>OE: {"message":{"content":"Dle anal√Ωzy ze dne..."}}
    OE-->>RS: string answer

    RS-->>API: AskResponseDto(answer, chunks[5], HasEmbeddings=true)
    API-->>UI: 200 OK  {answer, chunks}
    UI-->>User: "Dle z√°znamu z prohl√≠dky..."
```

### 5.6 Vektorov√© indexy a SQL

#### IVFFlat ‚Äì `listing_analyses.embedding`

```sql
-- Vhodn√Ω pro dynamicky rostouc√≠ sadu (tis√≠ce anal√Ωz)
-- Rychl√Ω build, m√≠rnƒõ ni≈æ≈°√≠ p≈ôesnost ‚Üí vyn√°hr√°zeno in-memory rerankem
CREATE INDEX IF NOT EXISTS idx_listing_analyses_embedding
    ON re_realestate.listing_analyses
    USING ivfflat (embedding vector_cosine_ops)
    WITH (lists = 100);
```

> `lists = 100` ‚Äì poƒçet Voronoi bunƒõk. Pravidlo palce: `sqrt(poƒçet_≈ô√°dk≈Ø)`.
> P≈ôi hled√°n√≠ se prohled√° `nprobes` bunƒõk (default 1 ‚Äì nav√Ω≈°it pro vy≈°≈°√≠ recall).

#### HNSW ‚Äì `listings.description_embedding` (legacy OpenAI embeddingy)

```sql
-- P≈ôesnƒõj≈°√≠ pro velk√© statick√© datasety
-- Vy≈°≈°√≠ pamƒõ≈•ov√© n√°roky, pomalej≈°√≠ build, ale nejlep≈°√≠ ANN recall
CREATE INDEX idx_listings_description_embedding_hnsw
    ON re_realestate.listings
    USING hnsw (description_embedding vector_l2_ops)
    WITH (m = 16, ef_construction = 64);
```

#### Hybridn√≠ dotaz: SQL filtry + vektorov√© ≈ôazen√≠

```sql
-- Doporuƒçen√© po≈ôad√≠: nejd≈ô√≠ve redukuj B-tree/GIN/GIST, pak ≈ôaƒè vektorem
SELECT id, title, location_text, price, area_land,
       description_embedding <-> :query_embedding AS l2_distance
FROM   re_realestate.listings
WHERE  is_active   = true
  AND  region      = 'Jihomoravsk√Ω kraj'          -- B-tree partial index
  AND  price BETWEEN 2000000 AND 5000000           -- B-tree
  AND  description_embedding IS NOT NULL
ORDER  BY description_embedding <-> :query_embedding
LIMIT  20;
```

### 5.7 Cosine similarity ‚Äì matematika

Pgvector oper√°tor `<->` vrac√≠ **L2 (euklidovskou) vzd√°lenost**. Pro fin√°ln√≠ sk√≥re je pot≈ôeba p≈ôesn√° cosine similarity, kter√° l√©pe odpov√≠d√° s√©mantick√© bl√≠zkosti:

```
CosineSimilarity(a, b) = (a ¬∑ b) / (||a|| * ||b||)
                       = sum(a_i * b_i) / (sqrt(sum(a_i^2)) * sqrt(sum(b_i^2)))
```

V√Ωsledek je v intervalu `[-1, 1]`, kde `1.0` = identick√Ω s√©mantick√Ω prostor.

```csharp
// RagService.cs ‚Äì p≈ôesn√Ω v√Ωpoƒçet pro reranking
private static double CosineSimilarity(Vector vectorA, float[] b)
{
    var a   = vectorA.Memory.ToArray();       // float[768] z pgvector column
    double dot = 0, magA = 0, magB = 0;

    for (int i = 0; i < a.Length && i < b.Length; i++)
    {
        dot  += a[i] * (double)b[i];
        magA += a[i] * a[i];
        magB += b[i] * (double)b[i];
    }

    return (magA == 0 || magB == 0)
        ? 0.0
        : dot / (Math.Sqrt(magA) * Math.Sqrt(magB));
}
```

### 5.8 Fallback strategie

Pokud `IEmbeddingService.IsConfigured == false` (≈°patn√© ENV) nebo ≈æ√°dn√Ω chunk nem√° embedding, RAG **nekrachne** ‚Äì m√≠sto toho naƒçte v≈°echny anal√Ωzy jako flat kontext:

```mermaid
flowchart TD
    START["AskListingAsync()"] --> CHK{"embedding.IsConfigured?"}
    CHK -->|"ANO"| VEC["GetEmbeddingAsync(question)\nFindSimilarAsync() ANN\nCosineSimilarity rerank"]
    CHK -->|"NE"| FLAT["Naƒçti V≈†ECHNY anal√Ωzy\nbez vektorov√©ho ≈ôazen√≠"]
    VEC --> NOFIT{"0 chunks s embedding?"}
    NOFIT -->|"jsou"| GEN
    NOFIT -->|"nejsou"| FLAT
    FLAT --> GEN["BuildUserMessage()\nqwen2.5:14b ChatAsync()"]
    GEN --> RESP["AskResponseDto\nHasEmbeddings=false"]
```

---

## 6. Ollama Vision ‚Äì klasifikace fotek

### 6.1 Dvoupr≈Øchodov√° klasifikace

Ka≈æd√° fotka inzer√°tu projde **dvƒõma oddƒõlen√Ωmi vol√°n√≠mi** Ollama Vision (`llama3.2-vision:11b`). Dvoupr≈Øchodov√Ω design je z√°mƒõrn√Ω: `format: "json"` v prvn√≠m pr≈Øchodu zaruƒçuje strojovƒõ ƒçiteln√Ω v√Ωstup, ale omezuje d√©lku odpovƒõdi ‚Äì proto je popis (druh√Ω pr≈Øchod) bez `format: json`.

```mermaid
flowchart TD
    START["POST /api/photos/bulk-classify\nbatchSize=N  (max 50)"] --> FETCH["Naƒçti N fotek\nbez classification_label\n(stored_url nebo original_url)"]

    FETCH --> LOOP{"Pro ka≈ædou fotku"}

    LOOP --> DL["St√°hni obr√°zek\nRelativn√≠ cesta z stored_url\nFile.ReadAllBytes()\nConvert.ToBase64String()"]

    DL --> P1["Pr≈Øchod 1: JSON klasifikace\nmodel: llama3.2-vision:11b\nformat: 'json'\nnum_predict: 256\nprompt: viz n√≠≈æe"]

    P1 --> PARSE{"Parsuj JSON v√Ωstup\n(regex fallback: extrakce {...})"}

    PARSE -->|"OK"| SAVE1["Ulo≈æ:\nclassification_label\nclassification_confidence 0-1\nclassification_labels[]"]

    PARSE -->|"fallback"| DEF["classification_label = 'other'\nconfidence = 0.0"]

    SAVE1 --> P2["Pr≈Øchod 2: voln√Ω popis\nmodel: llama3.2-vision:11b\nbez format:json\nprompt: popis 1-2 vƒõty EN"]

    DEF --> P2

    P2 --> SAVE2["Ulo≈æ:\nphoto_description (EN text)\nclassified_at = now()"]

    SAVE2 --> LOOP

    LOOP --> DONE["200 OK\n{processed, succeeded, errors}"]
```

#### Prompt 1 ‚Äì strukturovan√° klasifikace

```json
{
  "model": "llama3.2-vision:11b",
  "prompt": "Analyze this real estate property photo.\nRespond ONLY with valid JSON:\n{\"category\":\"...\",\"labels\":[...],\"damage_detected\":false,\"confidence\":0.9}\n\ncategory: exterior|interior|kitchen|bathroom|living_room|bedroom|attic|basement|garage|land|floor_plan|damage|other\nlabels: 0-5 tags from: mold, water_damage, crack, broken_windows, damaged_roof, renovation_needed, garden, pool, fireplace, wooden_beams, new_construction, renovated, brick_walls, wooden_construction, panel_building\ndamage_detected: true if ANY visible damage\nconfidence: 0.0 to 1.0",
  "images": ["<base64>"],
  "format": "json",
  "stream": false,
  "num_predict": 256
}
```

#### Prompt 2 ‚Äì voln√Ω popis

```json
{
  "model": "llama3.2-vision:11b",
  "prompt": "Describe what you see in this real estate property photo in 1-2 sentences. Focus on materials, condition, size impression, and any notable features or defects. Be specific and concise.",
  "images": ["<base64>"],
  "stream": false
}
```

#### Prioritn√≠ ≈ôazen√≠ fotek (`sort-by-category`)

| Priorita | Kategorie | D≈Øvod |
|---|---|---|
| 1 | `exterior` | Prvn√≠ dojem z nemovitosti |
| 2 | `interior` / `living_room` | Hlavn√≠ obytn√Ω prostor |
| 3 | `kitchen` | Kuchynƒõ ‚Äì kl√≠ƒçov√° m√≠stnost |
| 4 | `bedroom` | Lo≈ænice ‚Äì poƒçet, velikost |
| 5 | `bathroom` | Stav koupelny |
| 6 | `garden` | Zahrada |
| 7 | `basement` / `attic` | Sklep / p≈Øda |
| 8 | `garage` | Gar√°≈æ |
| 9 | `floor_plan` | P≈Ødorys |
| 10 | `damage` | Po≈°kozen√≠ (z√°mƒõrnƒõ na konec) |
| 11 | `other` | Ostatn√≠ |
| 12 | neklasifikovan√© | Bez AI klasifikace |

### 6.2 Klasifikace fotek z prohl√≠dky

`POST /api/photos/bulk-classify-inspection?listingId={id}&batchSize=N`

Stejn√Ω dvoupr≈Øchodov√Ω mechanismus, ale pracuje s tabulkou `user_listing_photos` ‚Äì vlastn√≠ fotky po≈ô√≠zen√© p≈ôi fyzick√© prohl√≠dce nemovitosti.

### 6.3 Alt text (WCAG 2.2 AA)

`POST /api/photos/bulk-alt-text` generuje p≈ô√≠stupn√© ƒçesk√© popisky:

```
Prompt: "Generate a concise, descriptive alt text in Czech (max 150 chars)
         for this real estate property photo.
         Start with what is shown (e.g. 'Pohled na fas√°du...'). Be specific."

V√Ωsledek ‚Üí listing_photos.alt_text
P≈ô√≠klad:  "Pohled na fas√°du rodinn√©ho domu s dvojgar√°≈æ√≠ a malou p≈ôedzahr√°dkou"
```

Dekorativn√≠ ikony v UI dost√°vaj√≠ `aria-hidden="true"`, fotky bez alt textu zobrazuj√≠ fallback z category labelu.

---

## 7. Ollama Text ‚Äì AI funkce

V≈°echny ƒçty≈ôi textov√© funkce sd√≠l√≠ `IEmbeddingService.ChatAsync()` (‚Üí `qwen2.5:14b` nebo `llama3.2`) ‚Äì ≈æ√°dn√Ω vlastn√≠ HTTP klient.

```mermaid
flowchart LR
    subgraph BATCH["Batch REST endpointy"]
        B1["POST /api/ollama/bulk-smart-tags\nbatchSize=N"]
        B2["POST /api/ollama/bulk-normalize\nbatchSize=N"]
        B3["POST /api/ollama/bulk-price-opinion\nbatchSize=N"]
    end

    subgraph SINGLE["Single endpointy"]
        S1["POST /api/ollama/detect-duplicates\n{id1, id2}"]
    end

    B1 --> TAGS["Smart Tags\n5 tag≈Ø v ƒçe≈°tinƒõ\nJSON array"]
    B2 --> NORM["Normalizace\nrok stavby, patro, v√Ωtah,\nsklep, zahrada, energie...\nJSON objekt -> jsonb"]
    B3 --> PRICE["Cenov√Ω sign√°l\nlow | fair | high\n+ zd≈Øvodnƒõn√≠"]
    S1 --> DUP["Duplik√°ty\nbool + confidence + reason"]

    TAGS --> DB1["listings.smart_tags (text)\nlistings.smart_tags_at"]
    NORM --> DB2["listings.ai_normalized_data (jsonb)\nlistings.ai_normalized_at"]
    PRICE --> DB3["listings.price_signal (text)\nlistings.price_signal_reason\nlistings.price_signal_at"]
    DUP --> R1["DuplicateDetectionDto\nbool AreDuplicates\nfloat Confidence\nstring Reason"]
```

### 7.1 Smart Tags

```
System:
  "You are a Czech real estate data extractor.
   Extract exactly 5 short keyword tags from the listing description.
   Tags must be in Czech, lowercase, max 2 words each.
   Focus on: property features, amenities, construction type, condition, extras.
   Respond ONLY with valid JSON array: [\"tag1\",\"tag2\",\"tag3\",\"tag4\",\"tag5\"]"

User:
  "N√°zev: {title}\nPopis: {description[:2000]}"

Response ‚Üí ["novostavba","gar√°≈æ","zahrada","podkrov√≠","sklep"]
```

### 7.2 Normalizace dat

Extrakce strukturovan√Ωch pol√≠ z nestrukturovan√©ho popisu inzer√°tu:

```
System: "You are a Czech real estate data extractor.
         From the listing description, extract structured data as JSON.
         Respond ONLY with valid JSON (no explanation):
         {
           \"year_built\": 1985,
           \"floor\": 2,
           \"total_floors\": 4,
           \"has_elevator\": false,
           \"has_basement\": true,
           \"has_garage\": false,
           \"has_garden\": true,
           \"heating_type\": \"gas\",
           \"energy_class\": \"C\",
           \"is_single_floor\": false,
           \"has_storage\": true,
           \"extension_possible\": false
         }
         Use null for missing values."
```

V√Ωsledek ulo≈æen do `ai_normalized_data jsonb`. Vyu≈æ√≠v√°n v **badge syst√©mu** pro vizu√°ln√≠ hodnocen√≠ inzer√°tu.

### 7.3 Cenov√Ω sign√°l

```
System: "Czech real estate pricing expert.
         Tr≈æn√≠ ceny CZK/m¬≤:
         Praha: byt 80k-150k, d≈Øm 60k-120k
         Brno: byt 50k-90k, d≈Øm 40k-80k
         Region√°ln√≠: 20k-45k / Venkov: 5k-25k
         Return ONLY JSON: {\"signal\":\"low|fair|high\",\"reason\":\"...\"}"

Response ‚Üí {"signal":"low","reason":"Cena 1.2M za d≈Øm 120m¬≤ v T≈ôeb√≠ƒçi = 10 000 Kƒç/m¬≤, pod pr≈Ømƒõrem 15-25k/m¬≤"}
```

### 7.4 Detekce duplik√°t≈Ø

```
User: "Inzer√°t A:\nTitul: {titleA} | Cena: {priceA} | Lokalita: {locationA} | Plocha: {areaA} m¬≤
       Popis: {descA[:500]}

       Inzer√°t B:\nTitul: {titleB} | ...

       Jsou tyto inzer√°ty duplicitn√≠? (stejn√° nemovitost u v√≠ce makl√©≈ô≈Ø?)
       JSON: {\"are_duplicates\":true,\"confidence\":0.92,\"reason\":\"...\"}"
```

### 7.5 Robustn√≠ JSON parsov√°n√≠

LLM obƒças p≈ôid√° preambuli nebo postambuli mimo JSON. `OllamaTextService` pou≈æ√≠v√° fallback chain:

```mermaid
flowchart LR
    RAW["raw LLM response"] --> TRY1["1. JsonSerializer.Deserialize(response)\np≈ô√≠m√Ω parse"]
    TRY1 -->|"OK"| DONE["return T"]
    TRY1 -->|"fail"| TRY2["2. Regex extract\nprvn√≠ {...} nebo [...]"]
    TRY2 -->|"OK"| PARSE2["JsonSerializer.Deserialize(extracted)"]
    PARSE2 -->|"OK"| DONE
    PARSE2 -->|"fail"| TRY3["3. return default(T)\ngraceful degradation"]
    TRY2 -->|"nic nenalezeno"| TRY3
```

---

## 8. KN OCR ‚Äì Screenshot z katastru

U≈æivatel m≈Ø≈æe vlo≈æit screenshot z port√°lu [nahl√≠≈æen√≠dokn.cuzk.cz](https://nahlizenidokn.cuzk.cz) buƒè **Ctrl+V** (clipboard paste) nebo **drag&drop** / v√Ωbƒõr souboru. Ollama Vision extrahuje strukturovan√° katastr√°ln√≠ data.

### Tok cel√© featury end-to-end

```mermaid
sequenceDiagram
    actor User
    participant JS  as kn-ocr.js (browser)
    participant BLZ as ListingDetail.razor [JSInvokable]
    participant API as CadastreEndpoints.cs
    participant CS  as CadastreService.OcrScreenshotAsync()
    participant OL  as Ollama llama3.2-vision:11b
    participant DB  as listing_cadastre_data

    User->>JS: Ctrl+V screenshot z KN port√°lu
    JS->>JS: document.on('paste')\nclipboardData -> first image/* item\n_fileToBase64() -> strip data URL prefix
    JS->>BLZ: invokeMethodAsync("ReceivePastedImageAsync", base64, mimeType)
    BLZ->>BLZ: _ocrPreviewSrc = "data:image/png;base64,..." -> render preview
    BLZ->>API: multipart/form-data\n{ file: bytes }
    API->>API: Validace: ContentType starts with "image/"\nmax 20 MB
    API->>CS: OcrScreenshotAsync(listingId, imageBytes)

    CS->>OL: POST /api/generate\n{ model: "llama3.2-vision:11b",\n  prompt: KN extraction prompt,\n  images: [base64],\n  format: "json",\n  num_predict: 1024,\n  stream: false }

    OL-->>CS: {"response":"{ \"parcel_number\":\"60\", \"lv_number\":\"1088\",\n  \"land_area_m2\":1250, \"land_type\":\"zahrada\",\n  \"municipality\":\"≈†t√≠tary\",\n  \"encumbrances\":[{\"type\":\"vƒõcn√© b≈ôemeno\",\"desc\":\"...\"}] }"}

    CS->>CS: Deserialize KnOcrData (SnakeCaseLower)
    CS->>DB: UPSERT listing_cadastre_data\n(parcel_number, lv_number, land_area_m2,\n land_type, municipality, fetch_status='ocr')
    DB-->>CS: OK
    CS-->>API: CadastreOcrResultDto(cadastre, rawJson)
    API-->>BLZ: 200 OK  OcrResultWrapper
    BLZ->>BLZ: _ocrParsed = result.Cadastre\nSnackbar "OCR dokonƒçeno"
    BLZ-->>User: Tabulka: parceln√≠ ƒç., LV, v√Ωmƒõra, druh, vlastn√≠k + seznam vƒõcn√Ωch b≈ôemen
```

#### KN Extraction Prompt

```
Extract structured data from this Czech cadastre (katastr nemovitost√≠) screenshot.
Return ONLY valid JSON:
{
  "parcel_number": "60",
  "lv_number": "1088",
  "land_area_m2": 1250,
  "land_type": "zahrada",
  "municipality": "≈†t√≠tary",
  "cadastral_area": "≈†t√≠tary",
  "owner_info": "Jan Nov√°k",
  "protection": null,
  "encumbrances": [
    {"type": "vƒõcn√© b≈ôemeno", "description": "pr√°vo ch≈Øze a j√≠zdy", "beneficiary": "sousedn√≠ parcela"}
  ],
  "building_number": null,
  "building_type": null
}
Use null for any field not visible in the screenshot.
Focus on: Parceln√≠ ƒç√≠slo, ƒå√≠slo LV, V√Ωmƒõra, Druh pozemku, Vlastn√≠ci, Vƒõcn√° b≈ôemena, Z√°stavn√≠ pr√°va.
```

### JS interop ‚Äì `kn-ocr.js`

```mermaid
flowchart TD
    INIT["knOcr.init(dotNetRef, elementId)"] --> PASTE_L["document.addEventListener('paste',...)\nglob√°ln√≠ ‚Äì zachyt√≠ i Ctrl+V mimo element"]
    INIT --> DRAG_L["element.addEventListener('dragover',...)\nelement.addEventListener('drop',...)"]

    PASTE_L --> EXT_P["e.clipboardData.items[]\nhledej prvn√≠ image/* type\nFileReader.readAsDataURL()"]
    DRAG_L --> EXT_D["e.dataTransfer.files[0]\nhledej prvn√≠ image/* type\nFileReader.readAsDataURL()"]

    EXT_P --> BASE64["_fileToBase64(file)\n= dataURL.split(',')[1]\nstrip 'data:image/png;base64,'"]
    EXT_D --> BASE64

    BASE64 --> INVOKE["dotNetRef.invokeMethodAsync(\n  'ReceivePastedImageAsync',\n  base64, mimeType\n)"]

    INVOKE --> BLAZOR["[JSInvokable] ReceivePastedImageAsync()\n-> _ocrPreviewSrc nastavit\n-> ProcessOcrImageAsync() volat"]

    DISPOSE["knOcr.dispose()\n-> removeEventListener paste\n-> removeEventListener dragover, drop"]
```

---

## 9. Prostorov√© vyhled√°v√°n√≠ (PostGIS)

### 9.1 Koridorov√© filtrov√°n√≠

Umo≈æ≈àuje naj√≠t inzer√°ty **pod√©l trasy** (nap≈ô. ≈†t√≠tary ‚Üí Poho≈ôelice, buffer 5 km).

```mermaid
flowchart TD
    UI_MAP["Map.razor\nstart: ≈†t√≠tary\nend: Poho≈ôelice\nbuffer: 5 000 m"]

    UI_MAP --> BUILD["POST /api/spatial/build-corridor\n{startCity, endCity, bufferMeters, useOsrm}"]

    BUILD --> GEOCODE_S["Nominatim geocode\nstart -> (lat1, lng1)\nend -> (lat2, lng2)"]
    GEOCODE_S --> OSRM_CALL["OSRM routing\nGET /route/v1/driving/{lng1,lat1};{lng2,lat2}\n?overview=full&geometries=polyline"]
    OSRM_CALL --> DECODE["Decode Encoded Polyline\n-> List<(lat,lng)> body trasy"]

    DECODE --> PG_BUF["PostGIS pipeline:\n1. ST_GeomFromText(LINESTRING(...), 4326)\n2. ST_Transform(geom, 5514)  EPSG:5514 S-JTSK metrick√Ω CZ\n3. ST_Buffer(geom_5514, bufferMeters)\n4. ST_Transform(buffer, 4326)  zpƒõt do WGS84\n5. ST_AsText(polygon)"]

    PG_BUF --> SAVE_AREA["INSERT INTO spatial_areas\n{name, geom polygon, area_type='corridor',\nstart_city, end_city, buffer_m}"]

    SAVE_AREA --> SEARCH["POST /api/spatial/search-in-area\n{areaId}"]
    SEARCH --> INTERSECT["SELECT l.* FROM listings l\nJOIN spatial_areas a ON a.id={areaId}\nWHERE ST_Intersects(l.location_point, a.geom)\n  AND l.is_active = true"]

    INTERSECT --> RESULTS["List<ListingSummaryDto>\nbez str√°nkov√°n√≠"]
    RESULTS --> LEAFLET["Map.razor Leaflet\nbarevn√© markery dle\nproperty_type + offer_type"]
```

> **Proƒç EPSG:5514?** PostGIS `ST_Buffer` pracuje v jednotk√°ch projekce. WGS84 je ve stupn√≠ch ‚Üí buffer v metrech by byl nep≈ôesn√Ω. EPSG:5514 (S-JTSK K≈ôov√°k) je metrick√° projekce optimalizovan√° pro ƒåR ‚Äì p≈ôesnost ~1 cm / 100 km.

### 9.2 Geocoding pipeline

```mermaid
flowchart LR
    L["listing.location_text"] --> S1{"Scraper\nextrahoval GPS?"}
    S1 -->|"ANO"| SCRAPER_GPS["source = 'scraper'\nnejp≈ôesnƒõj≈°√≠ (metadata webu)"]
    S1 -->|"NE"| HEU["ExtractCityFromLocationText()\nheuristika"]

    subgraph HEU_RULES["Heuristiky (regex)"]
        R1["'Znojmo, P≈ô√≠mƒõtick√° 48' -> 'Znojmo'"]
        R2["'Praha 6 - Dejvice' -> 'Praha 6'"]
        R3["p≈ôed prvn√≠ ƒç√≠slic√≠ nebo ƒç√°rkou"]
    end

    HEU --> NOM["Nominatim API\nhttps://nominatim.openstreetmap.org/search\n?q={city}&format=json&limit=1\nRate limit: 1.1 s / request"]
    NOM -->|"nalezeno"| UPD["UPDATE listings SET\nlatitude, longitude,\ngeocode_source='nominatim'"]
    NOM -->|"nenalezeno"| SKIP["P≈ôeskoƒçit\n(32 inzer√°t≈Ø nelze geoc√≥dovat)"]

    UPD --> TRIG["TRIGGER sync_location_point\nUPDATE location_point =\nST_SetSRID(ST_MakePoint(lng,lat),4326)"]
```

**Stav:** 1 366 / 1 416 (97 %) ‚Äî 1 346 Nominatim, 20 scraper GPS.

---

## 10. DB sch√©ma (ERD)

```mermaid
erDiagram
    sources {
        uuid   id        PK
        text   code      UK
        text   name
        text   base_url
        bool   is_active
        text   scraper_type
        ts     created_at
        ts     updated_at
    }

    listings {
        uuid    id                PK
        uuid    source_id         FK
        text    source_code
        text    external_id
        text    url               UK
        text    title
        text    description
        text    location_text
        text    region
        text    district
        text    municipality
        text    property_type
        text    offer_type
        numeric price
        int     area_built_up
        int     area_land
        int     rooms
        text    disposition
        bool    has_kitchen
        text    construction_type
        text    condition
        bool    is_active
        float8  latitude
        float8  longitude
        geom    location_point
        text    geocode_source
        tsvec   search_tsv
        vector  description_embedding
        text    smart_tags
        jsonb   ai_normalized_data
        text    price_signal
        text    price_signal_reason
        ts      first_seen_at
        ts      last_seen_at
    }

    listing_photos {
        uuid  id                      PK
        uuid  listing_id              FK
        text  original_url
        text  stored_url
        int   order_index
        text  classification_label
        float classification_confidence
        text  photo_description
        text  alt_text
        text  classification_feedback
        ts    classified_at
        ts    created_at
    }

    listing_analyses {
        uuid   id         PK
        uuid   listing_id FK
        text   content
        text   title
        text   source
        vector embedding
        ts     created_at
        ts     updated_at
    }

    user_listing_state {
        uuid  id           PK
        uuid  user_id
        uuid  listing_id   FK
        text  status
        text  notes
        ts    last_updated
    }

    user_listing_photos {
        uuid   id                 PK
        uuid   listing_id         FK
        text   stored_url
        text   original_file_name
        int8   file_size_bytes
        ts     taken_at
        ts     uploaded_at
        text   notes
        text   classification_label
        float  classification_confidence
        text   photo_description
        ts     classified_at
    }

    listing_cadastre_data {
        uuid  id              PK
        uuid  listing_id      FK
        int8  ruian_kod
        text  parcel_number
        text  lv_number
        int   land_area_m2
        text  land_type
        text  owner_type
        text  encumbrances_json
        text  address_searched
        text  cadastre_url
        text  fetch_status
        text  fetch_error
        ts    fetched_at
    }

    analysis_jobs {
        uuid  id               PK
        uuid  listing_id       FK
        uuid  user_id
        text  status
        text  storage_provider
        text  storage_url
        ts    requested_at
        ts    finished_at
        text  error_message
    }

    scrape_runs {
        uuid  id                 PK
        uuid  source_id          FK
        text  source_code
        text  status
        int   total_seen
        int   total_new
        int   total_updated
        int   total_inactivated
        ts    started_at
        ts    finished_at
    }

    scrape_jobs {
        uuid   id           PK
        text[] source_codes
        bool   full_rescan
        text   status
        int    progress
        int    listings_found
        int    listings_new
        ts     created_at
        ts     started_at
        ts     finished_at
    }

    spatial_areas {
        uuid  id          PK
        text  name
        text  area_type
        geom  geom
        text  start_city
        text  end_city
        int   buffer_m
        bool  is_active
        ts    created_at
        ts    updated_at
    }

    sources              ||--o{ listings              : "provides"
    listings             ||--o{ listing_photos        : "has"
    listings             ||--o{ listing_analyses      : "has"
    listings             ||--o{ user_listing_state    : "tracked by"
    listings             ||--o{ user_listing_photos   : "inspected with"
    listings             ||--o{ analysis_jobs         : "exported via"
    listings             ||--o|  listing_cadastre_data : "described in KN"
    sources              ||--o{ scrape_runs           : "tracked in"
```

### Indexov√° strategie

| Index | Tabulka | Typ | √öƒçel |
|---|---|---|---|
| `idx_listings_active_region_price` | listings | B-tree (partial) | Z√°kladn√≠ filtrov√°n√≠ |
| `idx_listings_search_tsv` | listings | GIN | Plnotextov√© vyhled√°v√°n√≠ |
| `idx_listings_description_embedding_hnsw` | listings | HNSW (m=16, ef_c=64) | S√©mantick√© vyhled√°v√°n√≠ |
| `idx_listings_location_point` | listings | GIST (partial) | Prostorov√© dotazy |
| `idx_listing_analyses_embedding` | listing_analyses | IVFFlat (lists=100) | RAG retrieval |
| `idx_listing_photos_listing_id` | listing_photos | B-tree | JOIN fotky |
| `idx_spatial_areas_geom` | spatial_areas | GIST | ST_Intersects |

---

## 11. API endpoint reference

> V≈°echny endpointy na `http://localhost:5001`. Scraping endpointy vy≈æaduj√≠ `X-Api-Key` header.

### Listings

| Metoda | Cesta | Popis |
|---|---|---|
| `POST` | `/api/listings/search` | Str√°nkovan√© filtrov√°n√≠ (JSON `ListingFilterDto`) |
| `GET` | `/api/listings/{id}` | Detail + fotky + AI pole + katastr |
| `GET` | `/api/listings/export.csv` | CSV export (UTF-8 BOM, `;`, max 5 000) |
| `GET` | `/api/listings/my-listings` | Skupiny dle user stavu |
| `GET` | `/api/listings/{id}/export-content` | Export bal√≠ƒçek (MD + JSON + foto URL) |
| `GET` | `/api/listings/{id}/inspection-photos` | Fotky z prohl√≠dky |

### Photos

| Metoda | Cesta | Popis |
|---|---|---|
| `POST` | `/api/photos/bulk-classify` | Vision klasifikace inzer√°tn√≠ch fotek |
| `POST` | `/api/photos/bulk-classify-inspection` | Vision klasifikace fotek z prohl√≠dky |
| `POST` | `/api/photos/sort-by-category` | P≈ôe≈ôadit `order_index` dle priority |
| `POST` | `/api/photos/bulk-alt-text` | Generovat WCAG 2.2 AA alt texty |
| `PATCH` | `/api/photos/{id}/classification-feedback` | Feedback `correct`/`wrong` |
| `POST` | `/api/photos/bulk-download` | St√°hnout fotky do lok√°ln√≠ho storage |
| `GET` | `/api/photos/stats` | Statistiky sta≈æen√Ωch fotek |

### Ollama Text

| Metoda | Cesta | Popis |
|---|---|---|
| `POST` | `/api/ollama/bulk-smart-tags` | 5 tag≈Ø pro N inzer√°t≈Ø |
| `POST` | `/api/ollama/bulk-normalize` | AI normalizace (rok, patro, v√Ωtah‚Ä¶) |
| `POST` | `/api/ollama/bulk-price-opinion` | Cenov√Ω sign√°l low/fair/high |
| `POST` | `/api/ollama/detect-duplicates` | Detekce duplik√°t≈Ø `{id1, id2}` |
| `GET` | `/api/ollama/stats` | Poƒçty zpracovan√Ωch AI pol√≠ |

### RAG

| Metoda | Cesta | Popis |
|---|---|---|
| `POST` | `/api/rag/ask-listing/{id}` | Chat nad konkr√©tn√≠m inzer√°tem |
| `POST` | `/api/rag/ask` | Cross-listing s√©mantick√Ω dotaz |
| `POST` | `/api/rag/embed/{id}` | Embedovat popis inzer√°tu (source=auto) |
| `POST` | `/api/rag/bulk-embed` | Bulk indexace `?limit=N` |
| `GET` | `/api/rag/analyses/{id}` | V≈°echny anal√Ωzy inzer√°tu |
| `DELETE` | `/api/rag/analyses/{analysisId}` | Smazat anal√Ωzu |

### Katastr

| Metoda | Cesta | Popis |
|---|---|---|
| `POST` | `/api/cadastre/single` | R√öIAN lookup pro jeden inzer√°t |
| `POST` | `/api/cadastre/bulk` | Bulk R√öIAN lookup |
| `GET` | `/api/cadastre/stats` | Statistiky KN dat |
| `POST` | `/api/cadastre/listings/{id}/ocr-screenshot` | **OCR screenshotu z KN** (multipart, max 20 MB) |

### Spatial

| Metoda | Cesta | Popis |
|---|---|---|
| `POST` | `/api/spatial/build-corridor` | Vytvo≈ôit koridor (OSRM + ST_Buffer) |
| `POST` | `/api/spatial/search-in-area` | Inzer√°ty v ulo≈æen√© oblasti |
| `GET` | `/api/spatial/areas` | V≈°echny ulo≈æen√© oblasti |
| `POST` | `/api/spatial/bulk-geocode` | Bulk geocoding (Nominatim) |
| `GET` | `/api/spatial/map-points` | GPS body pro Leaflet mapu |

### Scraping (X-Api-Key required)

| Metoda | Cesta | Popis |
|---|---|---|
| `POST` | `/api/scraping/trigger` | Spustit scraping job |
| `GET` | `/api/scraping/jobs` | Seznam job≈Ø |
| `GET` | `/api/scraping/jobs/{id}` | Detail jobu (progress %) |
| `GET` | `/api/sources` | Seznam zdroj≈Ø |

### Export / AI anal√Ωza

| Metoda | Cesta | Popis |
|---|---|---|
| `POST` | `/api/export/google-drive/{id}` | Export do Google Drive |
| `POST` | `/api/export/onedrive/{id}` | Export do OneDrive |

---

## 12. MCP Tools ‚Äì Claude Desktop integrace

```mermaid
flowchart LR
    subgraph CLAUDE["Claude Desktop (MCP Client)"]
        USER_C["U≈æivatel\n'Najdi domy kolem 3M v Znojmƒõ'"]
    end

    subgraph MCP_SRV["realestate-mcp :8002\nPython FastAPI SSE"]
        TOOLS["search_listings\nget_listing\nget_analyses\nget_inspection_photos\nsave_analysis"]
    end

    subgraph API_SRV["realestate-api :5001"]
        E1["GET /api/listings/search"]
        E2["GET /api/listings/{id}"]
        E3["GET /api/rag/analyses/{id}"]
        E4["GET /api/listings/{id}/inspection-photos"]
        E5["POST /api/rag/analyses (save + embed)"]
    end

    USER_C -->|"tool call"| TOOLS
    TOOLS -->|HTTP| E1
    TOOLS -->|HTTP| E2
    TOOLS -->|HTTP| E3
    TOOLS -->|HTTP| E4
    TOOLS -->|HTTP| E5
```

### MCP Tools reference

| Tool | R/W | Popis |
|---|---|---|
| `search_listings` | R | Vyhled√°v√°n√≠ dle query, filtr≈Ø |
| `get_listing` | R | Kompletn√≠ detail + **Z√ÅPIS Z PROHL√çDKY** + Drive URL |
| `get_analyses` | R | V≈°echny anal√Ωzy inzer√°tu (pln√Ω text, bez zkr√°cen√≠) |
| `get_inspection_photos` | R | Fotky z prohl√≠dky (user_listing_photos) |
| `save_analysis` | W | Ulo≈æit anal√Ωzu ‚Üí DB + auto pgvector embedding |

**Kl√≠ƒçov√© vlastnosti:**
- `source="claude"` je automaticky p≈ôi≈ôazeno p≈ôi `save_analysis`
- Ka≈æd√° ulo≈æen√° anal√Ωza dostane pgvector embedding ‚Üí prohled√°vateln√° p≈ôes RAG
- `get_listing` vrac√≠ `DriveFolderUrl` a `DriveInspectionFolderUrl` pro p≈ô√≠m√Ω p≈ô√≠stup k export≈Øm

---

## 13. Export pipeline (Google Drive / OneDrive)

```mermaid
flowchart TD
    TRIG["POST /api/export/google-drive/{id}\nnebo /api/export/onedrive/{id}"]

    TRIG --> BUILD["ListingExportContentBuilder\n.BuildInfoMarkdown()   -> README.md\n.BuildDataJson()       -> data.json\n.BuildAiInstructions() -> instrukce.md\n.BuildPhotoLinks()     -> photo-links.txt"]

    BUILD --> TEMPLATE["≈†ablony z /app/Templates/:\nai_instrukce_existing.md\nai_instrukce_newbuild.md\n(IsNewBuild() detekce dle kl√≠ƒçov√Ωch slov)"]

    BUILD --> PHOTOS["Inline fotky pro AI chat\nmax 10 fotek -> base64 v MD"]

    BUILD --> UPLOAD["GoogleDriveExportService\n/ OneDriveExportService\nNahr√°t 4 soubory do cloud slo≈æky"]

    UPLOAD --> UPDATE_JOB["UPDATE analysis_jobs\nstatus=Succeeded\nstorage_url = Drive folder URL"]

    UPDATE_JOB --> MCP_AVAIL["MCP get_listing\nvrac√≠ DriveFolderUrl\n-> Claude Desktop m≈Ø≈æe otev≈ô√≠t slo≈æku"]
```

---

## 14. Konfigurace a secrets

### Kl√≠ƒçov√© env promƒõnn√© (API kontejner)

| Promƒõnn√° | Default | Popis |
|---|---|---|
| `DB_HOST` | `localhost` | Postgres host (Docker: `realestate-db`) |
| `DB_PORT` | `5432` | Postgres port |
| `OLLAMA_BASE_URL` | ‚Äì | `http://host.docker.internal:11434` |
| `Ollama__EmbeddingModel` | `nomic-embed-text` | Embedding model |
| `Ollama__ChatModel` | `qwen2.5:14b` | Chat model |
| `Ollama__VisionModel` | `llama3.2-vision:11b` | Vision model |
| `Embedding__Provider` | `ollama` | `ollama` nebo `openai` |
| `Embedding__VectorDimensions` | `768` | Dimenze vektoru |
| `API_KEY` | `dev-key-change-me` | Kl√≠ƒç pro scraping endpointy |
| `SCRAPER_API_BASE_URL` | `http://localhost:8001` | Python scraper URL |
| `PHOTOS_PUBLIC_BASE_URL` | `http://localhost:5001` | Ve≈ôejn√° URL pro fotky |

### Secrets (./secrets/)

| Soubor | Obsah |
|---|---|
| `google-drive-sa.json` | Google Drive service account credentials |
| `google-drive-token.json` | OAuth2 access token (zapisuje callback handler) |
| `onedrive-token.json` | Microsoft OneDrive OAuth token |

---

## 15. Monitoring a logging

### Serilog structured logging

```mermaid
flowchart LR
    CODE["Aplikaƒçn√≠ k√≥d\nILogger<T>.LogInformation(...)"] --> S["Serilog pipeline\nbootstrap logger\n(chyby p≈ôed DI)"]

    S --> ENV{"ASPNETCORE_ENVIRONMENT?"}
    ENV -->|Development| CON["ColoredConsole\ns SourceContext\nƒçiteln√© pro v√Ωvoj"]
    ENV -->|Production| JSON["CompactJsonFormatter\nJSON na stdout\n/app/logs/*.json"]

    S --> HTTP["UseSerilogRequestLogging()\nHTTP Method x Path x StatusCode x ms"]
```

**MinimumLevel overrides:**

| Namespace | Level |
|---|---|
| Default | `Information` |
| `Microsoft.EntityFrameworkCore` | `Warning` |
| `Microsoft.AspNetCore` | `Warning` |
| `System.Net.Http` | `Warning` |

Bootstrap logger zachyt√≠ p√°dy **p≈ôed inicializac√≠ DI** ‚Äì `Log.Fatal()` + `Log.CloseAndFlush()` v `try/catch` wrapperu v `Program.cs`.

### Scrape Run monitoring (SQL)

```sql
SELECT source_code,
       total_seen, total_new, total_updated, total_inactivated,
       EXTRACT(EPOCH FROM (finished_at - started_at)) AS duration_sec,
       started_at
FROM   re_realestate.v_scrape_run_stats
ORDER  BY started_at DESC
LIMIT  20;
```

---

## 16. V√Ωkonnostn√≠ tipy & indexov√° strategie

### pgvector tuning

```sql
-- IVFFlat: vy≈°≈°√≠ recall za cenu pomalej≈°√≠ho dotazu
SET ivfflat.probes = 10;   -- default 1 (prohled√° 10 bunƒõk m√≠sto 1)

-- HNSW: p≈ôesnƒõj≈°√≠ index, pomalej≈°√≠ build
CREATE INDEX ... USING hnsw (...) WITH (m = 32, ef_construction = 128);
-- m = poƒçet spojen√≠ v grafu (v√Ωchoz√≠ 16)
-- ef_construction = velikost search listu p≈ôi buildu (v√Ωchoz√≠ 64)

-- Reindex po hromadn√©m insertu
REINDEX INDEX CONCURRENTLY idx_listings_description_embedding_hnsw;
```

### Doporuƒçen√© po≈ôad√≠ filtr≈Ø

SQL filtrov√°n√≠ se ≈ô√≠d√≠ cenou operace. Levn√© filtry redukuj√≠ dataset pro dra≈æ≈°√≠:

```
1. WHERE is_active = true AND region = '...' AND price BETWEEN ... AND ...
   ‚Üí B-tree partial index (idx_listings_active_region_price)
   ‚Üí redukce na ~200-500 ≈ô√°dk≈Ø

2. AND search_tsv @@ plainto_tsquery('czech', :query)
   ‚Üí GIN index (idx_listings_search_tsv)
   ‚Üí redukce na ~10-50 ≈ô√°dk≈Ø

3. AND ST_Intersects(location_point, :corridor_geom)
   ‚Üí GIST index (idx_listings_location_point)
   ‚Üí redukce na inzer√°ty v koridoru

4. ORDER BY description_embedding <-> :queryVec LIMIT 20
   ‚Üí HNSW/IVFFlat ANN ‚Äì v≈ædy jako POSLEDN√ç na nejmen≈°√≠ podmno≈æinƒõ
```

### Docker rebuild (po ka≈æd√© zmƒõnƒõ C# k√≥du!)

```bash
docker compose build --no-cache app api && docker compose up -d --no-deps app api
```

> **Zapomenut√Ω rebuild = star√Ω k√≥d v kontejnerech.** V≈ædy rebuild po zmƒõnƒõ C# k√≥du.

### Embedding batch size

| Model | Throughput (CPU) | Doporuƒçen√Ω batch |
|---|---|---|
| `nomic-embed-text` | ~0.1 s / embedding | 50‚Äì100 / request |
| `llama3.2-vision:11b` | ~7 min / 50 fotek | 20‚Äì50 / request |
| `qwen2.5:14b` (chat) | ~4 min / 50 inzer√°t≈Ø | 50 / request |
| `llama3.2` (text) | ~2 min / 50 inzer√°t≈Ø | 50 / request |

---

*Dokumentace odpov√≠d√° stavu po Session 19 ‚Äì commit `9f17699` (27. 2. 2026).*
