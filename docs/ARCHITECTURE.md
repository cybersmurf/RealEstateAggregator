# RealEstateAggregator ‚Äì Architektura syst√©mu

> **Verze:** Session 17 (√∫nor 2026)  
> **√öƒçel:** Zevrubn√Ω technick√Ω popis cel√©ho syst√©mu ‚Äì stack, datov√Ω tok, RAG pipeline, AI funkce, DB sch√©ma, prostorov√© filtry, API.

---

## Obsah

1. [Executive Summary](#1-executive-summary)
2. [Technology Stack](#2-technology-stack)
3. [Syst√©mov√° architektura (Docker Compose)](#3-syst√©mov√°-architektura-docker-compose)
4. [Scraping pipeline](#4-scraping-pipeline)
5. [RAG ‚Äì Retrieval-Augmented Generation](#5-rag--retrieval-augmented-generation)
   - 5.1 [Ingestion pipeline](#51-ingestion-pipeline)
   - 5.2 [Retrieval pipeline](#52-retrieval-pipeline)
   - 5.3 [Generation pipeline](#53-generation-pipeline)
   - 5.4 [Sequence diagram ‚Äì pln√Ω RAG cyklus](#54-sequence-diagram--pln√Ω-rag-cyklus)
   - 5.5 [SQL ‚Äì vektorov√° podobnost](#55-sql--vektorov√°-podobnost)
   - 5.6 [Cosine similarity v pamƒõti](#56-cosine-similarity-v-pamƒõti)
6. [Ollama Vision ‚Äì klasifikace fotek](#6-ollama-vision--klasifikace-fotek)
7. [Ollama Text ‚Äì AI funkce](#7-ollama-text--ai-funkce)
8. [Prostorov√© vyhled√°v√°n√≠ (PostGIS)](#8-prostorov√©-vyhled√°v√°n√≠-postgis)
9. [DB sch√©ma (ERD)](#9-db-sch√©ma-erd)
10. [API endpoint reference](#10-api-endpoint-reference)
11. [Konfigurace a secrets](#11-konfigurace-a-secrets)
12. [Monitoring a logging](#12-monitoring-a-logging)
13. [V√Ωkonnostn√≠ tipy](#13-v√Ωkonnostn√≠-tipy)

---

## 1. Executive Summary

**RealEstateAggregator** je plnohodnotn√° ƒçesk√° realitn√≠ agregaƒçn√≠ platforma, kter√° kontinu√°lnƒõ stahuje inzer√°ty z **13 zdroj≈Ø** (SReality, iDnes, RE/MAX, CENTURY 21, M&M Reality, Prodejme.to, Premiera Reality, Delux Reality, HV Reality, Lexamo, Znojmo Reality, Nemovitosti Znojmo, Reas.cz), ukl√°d√° je do PostgreSQL s PostGIS a pgvector, a nab√≠z√≠:

| Schopnost | Technologie |
|-----------|-------------|
| Agregace inzer√°t≈Ø z 13 zdroj≈Ø | Python AsyncIO + httpx/BeautifulSoup |
| Plnotextov√© vyhled√°v√°n√≠ | PostgreSQL `tsvector` + GIN index |
| S√©mantick√© vyhled√°v√°n√≠ | pgvector HNSW (768-dim) + Ollama `nomic-embed-text` |
| RAG chat nad inzer√°ty | pgvector IVFFlat + Ollama `qwen2.5:14b` |
| Anal√Ωza fotek (AI Vision) | Ollama `llama3.2-vision:11b` |
| Smart tagy, cenov√Ω sign√°l, normalizace | Ollama `llama3.2` (text) |
| Prostorov√© filtrov√°n√≠ | PostGIS 3.4 (`ST_Buffer`, `ST_Intersects`) + OSRM routing |
| Katastr nemovitost√≠ | R√öIAN / ƒå√öZK REST API |
| MCP integrace pro Claude Desktop | Python FastAPI MCP server |
| Export pro AI anal√Ωzu | Google Drive / OneDrive export |

**Aktu√°ln√≠ stav:** ~1 403 aktivn√≠ch inzer√°t≈Ø, 97 % geoc√≥dov√°no (Nominatim + scraper GPS).

---

## 2. Technology Stack

### Backend

| Technologie | Verze | Role |
|-------------|-------|------|
| .NET / ASP.NET Core | 10.0 | API (Minimal API endpoints) + Blazor Server App |
| Entity Framework Core | 10.x | ORM, DB migrations, LINQ queries |
| Npgsql.EntityFrameworkCore.PostgreSQL | 10.x | PostgreSQL provider + pgvector support |
| Pgvector.EntityFrameworkCore | latest | EF Core vƒõktor typ `Vector` |
| NetTopologySuite | 2.x | Geometrick√© typy pro PostGIS v C# |
| Serilog.AspNetCore | 9.x | Strukturovan√© logov√°n√≠ (console/JSON) |

### Frontend

| Technologie | Verze | Role |
|-------------|-------|------|
| Blazor Server | .NET 10 | Interaktivn√≠ UI, real-time updates p≈ôes SignalR |
| MudBlazor | 9.x | UI komponenty (karty, filtry, dialog, mapa panel) |
| Leaflet.js | 1.x | Interaktivn√≠ mapa s markery a koridory |

### Datab√°ze

| Technologie | Verze | Role |
|-------------|-------|------|
| PostgreSQL | 15+ | Relaƒçn√≠ datab√°ze, schema `re_realestate` |
| PostGIS | 3.4 | Prostorov√° roz≈°√≠≈ôen√≠ (`geometry`, `GIST` index) |
| pgvector | 0.7+ | Vektorov√© embeddingy, `HNSW` a `IVFFlat` indexy |
| `uuid-ossp` | built-in | `gen_random_uuid()` pro UUIDs |

### AI / LLM

| Model | Typ | Dimenze | √öƒçel |
|-------|-----|---------|------|
| `nomic-embed-text` | Embedding | 768 | Embeddingy pro RAG anal√Ωzy (`listing_analyses.embedding`) |
| `qwen2.5:14b` | Chat LLM | ‚Äì | Generov√°n√≠ odpovƒõd√≠ v RAG chatu |
| `llama3.2-vision:11b` | Vision LLM | ‚Äì | Klasifikace fotek, alt text, popis fotek |
| `llama3.2` (text) | Chat LLM | ‚Äì | Smart tagy, cenov√Ω sign√°l, normalizace, detekce duplik√°t≈Ø |

> **Pozn√°mka:** Historicky byl pou≈æit OpenAI `text-embedding-3-small` (1536 dim) pro `listings.description_embedding`. Nov√Ω RAG stack bƒõ≈æ√≠ lok√°lnƒõ na Ollama (nomic-embed-text, 768 dim) v `listing_analyses.embedding`.

### Infrastructure

| Technologie | √öƒçel |
|-------------|------|
| Docker Compose | Orchestrace 5 slu≈æeb + pgAdmin (tools profile) |
| Colima / ARM64 | macOS Docker runtime (native ARM64, bez Rosetta) |
| OSRM | Open-source routing engine pro v√Ωpoƒçet koridor≈Ø |
| Nominatim (OSM) | Geocoding adres (open-source) |
| R√öIAN / ƒå√öZK | Katastr√°ln√≠ data a ovƒõ≈ôen√≠ parcel |
| APScheduler (Python) | Denn√≠ / t√Ωdenn√≠ pl√°nov√°n√≠ scrapingu |
| Google Drive / OneDrive | Cloud storage pro AI export bal√≠ƒçky |

---

## 3. Syst√©mov√° architektura (Docker Compose)

```mermaid
graph TB
    subgraph USER["üë§ U≈æivatel"]
        BROWSER["Prohl√≠≈æeƒç\nhttp://localhost:5002"]
        CLAUDE["Claude Desktop\n(MCP client)"]
    end

    subgraph DOCKER["üê≥ Docker Compose ‚Äì realestate-network"]
        APP["realestate-app\nBlazor Server :5002‚Üí8080\n.NET 10"]
        API["realestate-api\nASP.NET Core :5001‚Üí8080\n.NET 10 Minimal API"]
        SCRAPER["realestate-scraper\nPython FastAPI :8001\nAsyncIO + httpx"]
        DB["realestate-db\nPostgreSQL 15\nPostGIS 3.4 + pgvector\n:5432"]
        MCP["realestate-mcp\nPython FastAPI :8002\nMCP SSE server"]
        PGADMIN["pgadmin :5050\n(profile: tools)"]
    end

    subgraph EXTERNAL["üåê External Services"]
        OLLAMA["Ollama\nhttp://host.docker.internal:11434\nnomic-embed-text\nqwen2.5:14b\nllama3.2-vision:11b\nllama3.2"]
        OSRM["OSRM Router\nrouter.project-osrm.org"]
        NOMINATIM["Nominatim\nnominatim.openstreetmap.org"]
        RUIAN["R√öIAN / ƒå√öZK\ncuzk.cz REST API"]
        GDRIVE["Google Drive API\nExport bal√≠ƒçky"]
        ONEDRIVE["Microsoft OneDrive\nExport bal√≠ƒçky"]
        SITES["ƒåesk√© realitn√≠ weby\n13 zdroj≈Ø"]
    end

    subgraph VOLUMES["üíæ Docker Volumes"]
        PG_VOL["postgres_data\nPostgreSQL data"]
        UP_VOL["uploads_data\n/app/wwwroot/uploads\nFotky + exporty"]
        SECRETS_VOL["./secrets\nGoogle Drive\ncredentials"]
    end

    BROWSER -->|HTTP| APP
    APP -->|HTTP REST\nApiBaseUrl| API
    CLAUDE -->|MCP SSE :8002| MCP
    MCP -->|HTTP REST| API

    API -->|EF Core\nascpg| DB
    SCRAPER -->|asyncpg\ndirect SQL| DB
    API -->|HTTP REST\n:8001| SCRAPER
    API -->|HTTP :11434| OLLAMA
    MCP -->|HTTP :11434| OLLAMA

    API -->|HTTPS| GDRIVE
    API -->|HTTPS| ONEDRIVE
    API -->|HTTPS| RUIAN
    API -->|HTTPS| OSRM
    API -->|HTTPS| NOMINATIM
    SCRAPER -->|HTTP scraping| SITES

    DB --- PG_VOL
    API --- UP_VOL
    API --- SECRETS_VOL

    PGADMIN -->|TCP :5432| DB
```

### S√≠≈•ov√° komunikace (uvnit≈ô Dockeru)

| Caller | Callee | Adresa |
|--------|--------|--------|
| `app` | `api` | `http://realestate-api:8080` |
| `api` | `scraper` | `http://realestate-scraper:8001` |
| `api` / `mcp` | Ollama | `http://host.docker.internal:11434` |
| `api` / `scraper` | postgres | `postgres:5432` |

---

## 4. Scraping pipeline

### P≈ôehled toku dat

```mermaid
flowchart LR
    UI["Blazor UI\n/admin/scraping"] -->|POST /api/scraping/trigger\nX-Api-Key header| API_SCRAPE

    subgraph API_SCRAPE["API ‚Äì scraping endpoint"]
        AUTH["API Key Middleware\novƒõ≈ôen√≠ X-Api-Key"]
        JOB["Vytvo≈ôen√≠ scrape_jobs z√°znamu\nstatus=Queued"]
        FWD["Forward na Python\nPOST :8001/v1/scrape/run"]
    end

    subgraph PYTHON["Python Scraper (:8001)"]
        RUNNER["runner.py\nAsyncIO orchestr√°tor"]
        SCRAPERS["13√ó Scraper class\n_parse_list_page()\n_parse_detail_page()"]
        FILTER["FilterManager\ngeo filtr + kvalitativn√≠ filtr\ncenov√Ω limit"]
        DB_PY["database.py\nupsert_listing()\n_upsert_photos()"]
        SCHEDULER["APScheduler\ndenn√≠ 03:00\nt√Ωdenn√≠ full_rescan ne 02:00"]
    end

    subgraph DB_WRITE["PostgreSQL"]
        L_TBL["re_realestate.listings\nINSERT / UPDATE (upsert)"]
        P_TBL["re_realestate.listing_photos\nDELETE + INSERT (max 20/inzer√°t)"]
        SR_TBL["re_realestate.scrape_runs\nstatistika bƒõhu"]
        SJ_TBL["re_realestate.scrape_jobs\nprogress tracking"]
    end

    GEOCODER["Background: bulk-geocode\nPOST /api/spatial/bulk-geocode\nNominatim 1.1s rate limit"]

    AUTH --> JOB --> FWD --> RUNNER
    SCHEDULER --> RUNNER
    RUNNER --> SCRAPERS --> FILTER --> DB_PY
    DB_PY --> L_TBL & P_TBL & SR_TBL
    FWD --> SJ_TBL
    L_TBL -->|latitude/longitude\ntrigger: sync_location_point| GIST["location_point GIST\ngeometry(Point,4326)"]
    L_TBL -.->|listings bez GPS| GEOCODER
    GEOCODER -->|UPDATE lat/lng| L_TBL
```

### Upsert logika (Python)

Deduplikace inzer√°t≈Ø prob√≠h√° podle kompozitn√≠ho kl√≠ƒçe `(source_id, external_id)`:

```python
# database.py ‚Äì pseudok√≥d
existing = await conn.fetchrow(
    "SELECT id FROM re_realestate.listings "
    "WHERE source_id = $1 AND external_id = $2",
    source_id, external_id
)

if existing:
    await conn.execute("UPDATE re_realestate.listings SET ... WHERE id = $1", existing["id"])
else:
    listing_id = uuid4()
    await conn.execute("INSERT INTO re_realestate.listings (...) VALUES (...)")
```

### Deaktivace zanikl√Ωch inzer√°t≈Ø

P≈ôi `full_rescan=true` runner po dokonƒçen√≠ vol√° `deactivate_unseen_listings()` ‚Äì v≈°echny inzer√°ty zdroje, kter√© nebyly vidƒõt v aktu√°ln√≠m bƒõhu, dostanou `is_active=false`.

### Filtrovac√≠ pipeline (Python `FilterManager`)

```mermaid
flowchart TD
    RAW["Surov√Ω inzer√°t\n(z parse str√°nky)"] --> GEO_F

    GEO_F{"Geo filtr\n(je v JMK / Jihoƒçesk√Ω?)"} -->|PASS| QUAL_F
    GEO_F -->|REJECT| SKIP["‚õî zahozen"]

    QUAL_F{"Kvalitativn√≠ filtr\n(title, popis, cena nenulov√°?)"} -->|PASS| PRICE_F
    QUAL_F -->|REJECT| SKIP

    PRICE_F{"Cenov√Ω limit\nHouse: ‚â§10 M Kƒç\nLand: ‚â§5 M Kƒç\n‚àí1 = p≈ôeskoƒçit"} -->|PASS| UPSERT
    PRICE_F -->|REJECT| SKIP

    UPSERT["‚úÖ upsert_listing()"]
```

---

## 5. RAG ‚Äì Retrieval-Augmented Generation

RAG syst√©m umo≈æ≈àuje p≈ôirozenojazyƒçn√Ω chat nad ulo≈æen√Ωmi anal√Ωzami inzer√°t≈Ø. Skl√°d√° se ze t≈ô√≠ logicky oddƒõlen√Ωch pipeline: **ingestion** (vklad√°n√≠ text≈Ø do vektoru), **retrieval** (hled√°n√≠ relevantn√≠ho kontextu) a **generation** (generov√°n√≠ odpovƒõdi LLM).

```mermaid
graph LR
    subgraph ING["Ingestion Pipeline"]
        TEXT["Strukturovan√Ω text\nBuildListingText()"] --> EMB["nomic-embed-text\nOllama /api/embed\n768 dim float[]"]
        EMB --> PGVEC["listing_analyses\nembedding vector(768)\nIVFFlat index"]
    end

    subgraph RET["Retrieval Pipeline"]
        Q["Dotaz u≈æivatele"] --> QEMB["nomic-embed-text\nembedding dotazu"]
        QEMB --> COSINE["pgvector <-> L2 distance\nFROM listing_analyses\nORDER BY embedding <-> $vec\nLIMIT topK"]
        COSINE --> CHUNKS["Top-K chunks\n+ CosineSimilarity\nin-memory reranking"]
    end

    subgraph GEN["Generation Pipeline"]
        CHUNKS --> CTX["BuildUserMessage()\nkontext = listing info\n+ se≈ôazen√© chunky"]
        SP["BuildSystemPrompt()\nrole + jazyk + instrukce"] --> LLM["qwen2.5:14b\nOllama /api/chat"]
        CTX --> LLM
        LLM --> ANS["AskResponseDto\nanswer + chunks + HasEmbeddings"]
    end
```

### 5.1 Ingestion pipeline

#### Kde vznikaj√≠ anal√Ωzy

Anal√Ωzy (chunks) se ukl√°daj√≠ do `listing_analyses` t≈ôemi zp≈Øsoby:

| Zp≈Øsob | Source tag | Obsah |
|--------|-----------|-------|
| Automatick√° indexace popisu | `"auto"` | Strukturovan√Ω text z `BuildListingText()` |
| Manu√°ln√≠ ulo≈æen√≠ z Claude Desktop (MCP) | `"claude"` | Libovoln√Ω text ‚Äì v√Ωsledek anal√Ωzy AI |
| Ulo≈æen√≠ z UI pohledu | `"user"` | U≈æivatelovy pozn√°mky |

#### `BuildListingText()` ‚Äì ≈°ablona strukturovan√©ho textu

```
# {Title}
Typ: {PropertyType} | Nab√≠dka: {OfferType}
Cena: {Price} Kƒç
Lokalita: {LocationText}
Obec: {Municipality} | Okres: {District}
Dispozice: {Disposition} | Plocha zastavƒõn√°: {AreaBuiltUp} m¬≤ | Plocha pozemku: {AreaLand} m¬≤
Stav: {Condition} | Konstrukce: {ConstructionType}

## Popis
{Description}
```

Text je p≈ôed embeddingem zkr√°cen na **8 000 znak≈Ø** (limit `OllamaEmbeddingService`).

#### Idempotence `EmbedListingDescriptionAsync()`

```csharp
// Zabr√°n√≠ duplicitn√≠ indexaci
bool alreadyEmbedded = await db.ListingAnalyses
    .AnyAsync(a => a.ListingId == listingId && a.Source == "auto", ct);
if (alreadyEmbedded) return;
```

#### Bulk indexace `BulkEmbedDescriptionsAsync(limit)`

Vyhled√° aktivn√≠ inzer√°ty bez `source="auto"` anal√Ωzy, se≈ôad√≠ od nejnovƒõj≈°√≠ho (`FirstSeenAt` DESC) a indexuje v d√°vce size `limit`.

### 5.2 Retrieval pipeline

#### `FindSimilarAsync(query, topK, ct, listingId?)`

```sql
-- Listing-specifick√© vyhled√°v√°n√≠ (listingId IS NOT NULL)
SELECT * FROM re_realestate.listing_analyses
WHERE listing_id = {listingId}
  AND embedding IS NOT NULL
ORDER BY embedding <-> {queryVector}   -- L2 distance (pgvector oper√°tor)
LIMIT {topK};

-- Cross-listing vyhled√°v√°n√≠ (listingId IS NULL)
SELECT * FROM re_realestate.listing_analyses
WHERE embedding IS NOT NULL
ORDER BY embedding <-> {queryVector}
LIMIT {topK};
```

> **Implementaƒçn√≠ detail:** pgvector prov√°d√≠ aproximativn√≠ vyhled√°v√°n√≠ p≈ôes IVFFlat index (`vector_cosine_ops`). V√Ωsledky jsou pak se≈ôazeny p≈ôesnou **cosine similarity** v pamƒõti (viz 5.6).

#### Fallback p≈ôi chybƒõj√≠c√≠ch embedding√°ch

Pokud `embedding.IsConfigured == false` nebo ≈æ√°dn√Ω chunk nem√° embedding, `AskListingAsync` naƒçte **v≈°echny** anal√Ωzy inzer√°tu bez vektorov√©ho ≈ôazen√≠ a p≈ôed√° je jako flat kontext.

### 5.3 Generation pipeline

#### System prompt (konstantn√≠)

```
Jsi AI asistent pom√°haj√≠c√≠ s anal√Ωzou nemovitost√≠ v ƒåesk√© republice.
Odpov√≠d√°≈° v ƒçe≈°tinƒõ. Vych√°z√≠≈° v√Ωhradnƒõ z poskytnut√©ho kontextu (anal√Ωz inzer√°t≈Ø).
Pokud kontext neobsahuje dostateƒçn√© informace, ≈ôekni to otev≈ôenƒõ.
Buƒè konkr√©tn√≠, vƒõcn√Ω a struƒçn√Ω. P≈ôi odkazov√°n√≠ na zdroje uveƒè jejich po≈ôad√≠ [1], [2], atd.
```

#### User message struktura

```markdown
## Inzer√°t
{Title} | {LocationText} | {Price} Kƒç | {PropertyType} {OfferType}

## Ulo≈æen√© anal√Ωzy (kontext)

### Anal√Ωza [1]
{chunk_1_content}

### Anal√Ωza [2]
{chunk_2_content}

...

## Dotaz
{question}
```

#### `AskResponseDto` ‚Äì v√Ωstup

```csharp
record AskResponseDto(
    string Answer,
    List<AnalysisChunkDto> Chunks,  // top-K chunky s ContentExcerpt (max 300 znak≈Ø) + similarity score
    bool HasEmbeddings
);
```

### 5.4 Sequence diagram ‚Äì pln√Ω RAG cyklus

```mermaid
sequenceDiagram
    actor User
    participant UI as Blazor UI / Claude
    participant API as ASP.NET Core API
    participant RAG as RagService
    participant EMB as OllamaEmbeddingService
    participant OLLAMA as Ollama :11434
    participant DB as PostgreSQL (pgvector)

    User->>UI: "M√° tento d≈Øm dobr√© z√°klady?"
    UI->>API: POST /api/rag/ask-listing/{id}\n{ question, topK }

    API->>RAG: AskListingAsync(listingId, question, topK)

    Note over RAG,EMB: === RETRIEVAL ===
    RAG->>EMB: GetEmbeddingAsync(question)
    EMB->>OLLAMA: POST /api/embed\n{ model: "nomic-embed-text", input: question }
    OLLAMA-->>EMB: { embeddings: [[0.12, -0.45, ...]] }  ‚Üê 768 float[]
    EMB-->>RAG: float[]  queryFloats

    RAG->>DB: FROM listing_analyses\nWHERE listing_id = {id}\nORDER BY embedding <-> queryVector\nLIMIT topK
    DB-->>RAG: List<ListingAnalysis>  (raw IVFFlat v√Ωsledky)

    Note over RAG: In-memory reranking\nCosineSimilarity(chunk.Embedding, queryFloats)
    RAG->>RAG: sort by cosine similarity DESC

    Note over RAG,DB: === CONTEXT LOAD ===
    RAG->>DB: SELECT listing (Title, LocationText, Price, ...)
    DB-->>RAG: Listing entity

    Note over RAG,OLLAMA: === GENERATION ===
    RAG->>RAG: BuildSystemPrompt()
    RAG->>RAG: BuildUserMessage(question, listingContext, chunks)

    RAG->>EMB: ChatAsync(systemPrompt, userMessage)
    EMB->>OLLAMA: POST /api/chat\n{ model: "qwen2.5:14b",\n  messages: [system, user],\n  stream: false }
    OLLAMA-->>EMB: { message: { content: "Z√°klady domu..." } }
    EMB-->>RAG: string answer

    RAG-->>API: AskResponseDto(answer, chunks, HasEmbeddings=true)
    API-->>UI: 200 OK { answer, chunks }
    UI-->>User: "Dle anal√Ωzy z prohl√≠dky jsou z√°klady..."
```

### 5.5 SQL ‚Äì vektorov√° podobnost

#### IVFFlat index na `listing_analyses`

```sql
CREATE INDEX IF NOT EXISTS idx_listing_analyses_embedding
    ON re_realestate.listing_analyses
    USING ivfflat (embedding vector_cosine_ops)
    WITH (lists = 100);
```

> **IVFFlat vs HNSW:** `listing_analyses` pou≈æ√≠v√° IVFFlat (rychlej≈°√≠ build, vhodn√Ω pro ~tis√≠ce z√°znam≈Ø). `listings.description_embedding` pou≈æ√≠v√° HNSW (p≈ôesnƒõj≈°√≠, vhodn√Ω pro statick√© velk√© datasety).

#### HNSW index na `listings.description_embedding`

```sql
CREATE INDEX idx_listings_description_embedding_hnsw
    ON re_realestate.listings
    USING hnsw (description_embedding vector_l2_ops)
    WITH (m = 16, ef_construction = 64);
```

#### Hybridn√≠ dotaz: filtry + s√©mantick√© vyhled√°v√°n√≠

```sql
SELECT id, title, location_text, price, area_land,
       description_embedding <-> :query_embedding AS distance
FROM re_realestate.listings
WHERE is_active = true
  AND region = 'Jihomoravsk√Ω kraj'
  AND price BETWEEN 2000000 AND 5000000
  AND description_embedding IS NOT NULL
ORDER BY description_embedding <-> :query_embedding
LIMIT 20;
```

### 5.6 Cosine similarity v pamƒõti

Pgvector `<->` oper√°tor vrac√≠ **L2 (euklidovskou) vzd√°lenost**. Pro v√Ωsledn√© sk√≥re podobnosti se p≈ôepoƒç√≠t√°v√° p≈ôesn√° cosine similarity v C#:

```csharp
private static double CosineSimilarity(Vector vectorA, float[] b)
{
    var a = vectorA.Memory.ToArray();
    double dot = 0, magA = 0, magB = 0;
    for (int i = 0; i < a.Length && i < b.Length; i++)
    {
        dot  += a[i] * b[i];
        magA += a[i] * a[i];
        magB += b[i] * b[i];
    }
    return magA == 0 || magB == 0
        ? 0.0
        : dot / (Math.Sqrt(magA) * Math.Sqrt(magB));
}
```

V√Ωsledek je v intervalu `[-1, 1]`, kde `1.0 = identick√Ω vektor`.

---

## 6. Ollama Vision ‚Äì klasifikace fotek

### P≈ôehled

Pro ka≈ædou fotku inzer√°tu se volaj√≠ **dva pr≈Øchody** Ollama Vision modelu (`llama3.2-vision:11b`) p≈ôes endpoint `POST /api/generate` (Ollama legacy generate API).

```mermaid
flowchart TD
    START["POST /api/photos/bulk-classify\nbatchSize=N"] --> FETCH["Naƒçti N fotek\nbez classification_label"]

    FETCH --> LOOP{"Pro ka≈ædou fotku"}

    LOOP --> DL["St√°hni foto\n(stored_url nebo original_url)\nBase64 encode"]

    DL --> CALL1["üì∑ Pr≈Øchod 1 ‚Äì JSON klasifikace\nformat: json\nmodel: llama3.2-vision:11b"]

    CALL1 --> PARSE1{"Parsuj JSON v√Ωstup\n(robustn√≠ regex\nextract {...})"}

    PARSE1 -->|OK| SAVE1["Ulo≈æ:\nclassification_label\nclassification_confidence\nclassification_labels[]"]

    PARSE1 -->|fallback| DEFAULT["classification_label=other\nconfidence=0.0"]

    SAVE1 --> CALL2["üìù Pr≈Øchod 2 ‚Äì popis (alt text)\n≈Ω√°dn√© format=json\nmodel: llama3.2-vision:11b"]

    CALL2 --> SAVE2["Ulo≈æ:\nphoto_description\n(1-2 vƒõty EN)"]

    SAVE2 --> ALTTEXT_CHECK{"bulk-alt-text\nbyl vol√°n?"}
    ALTTEXT_CHECK -->|ANO| ULOZ_ALT["Ulo≈æ alt_text\n(CZ, max 150 znak≈Ø)\nWCAG 2.2 AA"]
    ALTTEXT_CHECK -->|NE| LOOP

    LOOP --> |"v≈°echny hotov√©"| DONE["200 OK\n{ processed, errors }"]
```

### Prompt 1 ‚Äì JSON klasifikace

```json
{
  "model": "llama3.2-vision:11b",
  "prompt": "Classify this real estate photo. Return ONLY valid JSON:\n{\"category\":\"...\",\"labels\":[...],\"damage_detected\":false,\"confidence\":0.95}\nCategories: exterior, interior_living, interior_kitchen, interior_bathroom, interior_bedroom, garden, basement, garage, floor_plan, other",
  "images": ["<base64>"],
  "format": "json",
  "stream": false
}
```

### Prompt 2 ‚Äì Voln√Ω popis

```json
{
  "model": "llama3.2-vision:11b",
  "prompt": "Describe this real estate photo in 1-2 sentences in English. Focus on what is visible.",
  "images": ["<base64>"],
  "stream": false
}
```

### Kategorie a prioritn√≠ ≈ôazen√≠ fotek

`POST /api/photos/sort-by-category` p≈ôe≈ôad√≠ `order_index` fotek podle priority:

| Priorita | Kategorie |
|----------|-----------|
| 1 | `exterior` |
| 2 | `interior_living` |
| 3 | `interior_kitchen` |
| 4 | `interior_bedroom` |
| 5 | `interior_bathroom` |
| 6 | `garden` |
| 7 | `basement` |
| 8 | `garage` |
| 9 | `floor_plan` |
| 10 | `other` |
| 11 | Neklasifikovan√© |

### Alt text ‚Äì WCAG 2.2 AA

`POST /api/photos/bulk-alt-text` generuje p≈ô√≠stupn√© ƒçesk√© popisky fotek:

```text
Prompt: "Generate a concise, descriptive alt text in Czech (max 150 chars) for this real estate photo. Start with what is shown."
‚Üí "Pohled na fas√°du rodinn√©ho domu s dvojgar√°≈æ√≠ a zahradou"
```

V√Ωsledek ulo≈æen do `listing_photos.alt_text`. Dekorativn√≠ ikony dost√°vaj√≠ `aria-hidden="true"`, fotky bez alt textu zobrazuj√≠ fallback z kategorie.

---

## 7. Ollama Text ‚Äì AI funkce

`OllamaTextService` vyu≈æ√≠v√° sd√≠lenou metodu `IEmbeddingService.ChatAsync(systemPrompt, userMessage)` ‚Äì ≈æ√°dn√Ω vlastn√≠ HTTP klient, v≈°e jde p≈ôes `qwen2.5:14b` (nebo `llama3.2`).

```mermaid
flowchart LR
    subgraph BATCH["Batch endpoints (POST)"]
        ST["POST /api/ollama/bulk-smart-tags\nbatchSize=N"] --> TAGS
        NRM["POST /api/ollama/bulk-normalize\nbatchSize=N"] --> NORM
        PO["POST /api/ollama/bulk-price-opinion\nbatchSize=N"] --> PRICE
    end

    subgraph SINGLE["Single endpoints (POST)"]
        DD["POST /api/ollama/detect-duplicates\n{ id1, id2 }"] --> DUP
    end

    TAGS["üìõ Smart Tags\nJSON: [tag1, tag2, ..., tag5]\n5 kl√≠ƒçov√Ωch pojm≈Ø"] --> DB_TAGS["smart_tags text\n(JSON ulo≈æeno as text)\nsmart_tags_at"]

    NORM["üîß Normalizace\nJSON: {year_built, floor,\nhas_elevator, has_basement,\nhas_garden, ...}"] --> DB_NORM["ai_normalized_data jsonb\nai_normalized_at"]

    PRICE["üí∞ Cenov√Ω sign√°l\nJSON: {signal, reason}\nsignal ‚àà {low, fair, high}"] --> DB_PRICE["price_signal text\nprice_signal_reason text\nprice_signal_at"]

    DUP["üîç Detekce duplik√°t≈Ø\nJSON: {are_duplicates, confidence,\nreason}"] --> RESP["DuplicateDetectionDto\nbool AreDuplicates\nfloat Confidence\nstring Reason"]
```

### Smart Tags ‚Äì prompt

```
System: "Jsi expert na ƒçeskou realitn√≠ terminologii."
User: "Na z√°kladƒõ popisu nemovitosti vygeneruj p≈ôesnƒõ 5 kl√≠ƒçov√Ωch tag≈Ø v ƒçe≈°tinƒõ.
Vra≈• POUZE JSON array: [\"tag1\",\"tag2\",\"tag3\",\"tag4\",\"tag5\"]

Popis:
{description}"
```

### Normalizace ‚Äì prompt

```
System: "Jsi expert na extrakci dat z realitn√≠ch popis≈Ø."
User: "Z popisu extrahuj strukturovan√° data. Vra≈• POUZE JSON:
{
  \"year_built\": 1985,
  \"floor\": 2,
  \"total_floors\": 4,
  \"has_elevator\": false,
  \"has_basement\": true,
  \"has_garage\": false,
  \"has_garden\": true,
  \"heating_type\": \"gas\",
  \"energy_class\": \"C\"
}
Pokud info chyb√≠, pou≈æij null. Popis: {description}"
```

### Cenov√Ω sign√°l ‚Äì prompt

Syst√©m zn√° tr≈æn√≠ ceny:

```
Praha: 80 000‚Äì150 000 Kƒç/m¬≤ (byt), 60 000‚Äì120 000 Kƒç/m¬≤ (d≈Øm)
Brno: 50 000‚Äì90 000 Kƒç/m¬≤ (byt), 40 000‚Äì80 000 Kƒç/m¬≤ (d≈Øm)
Region√°ln√≠ mƒõsta: 20 000‚Äì45 000 Kƒç/m¬≤
Venkov / vesnice: 5 000‚Äì25 000 Kƒç/m¬≤
```

V√Ωstup:
```json
{ "signal": "low", "reason": "Cena 1.2M za d≈Øm 120m¬≤ v T≈ôeb√≠ƒçi odpov√≠d√° 10 000 Kƒç/m¬≤, co≈æ je pod region√°ln√≠m pr≈Ømƒõrem 15-25 000 Kƒç/m¬≤." }
```

### Detekce duplik√°t≈Ø ‚Äì vstup

Porovn√°vaj√≠ se dva inzer√°ty s cel√Ωm kontextem:

```
Inzer√°t A:
Titul: {titleA} | Cena: {priceA} Kƒç | Lokalita: {locationA} | Plocha: {areaA} m¬≤
Popis: {descriptionA[:500]}

Inzer√°t B:
...

Jsou tyto inzer√°ty duplicitn√≠ nebo r≈Øzn√© nab√≠dky stejn√© nemovitosti?
JSON: { "are_duplicates": true, "confidence": 0.92, "reason": "..." }
```

### Robustn√≠ JSON parsov√°n√≠

LLM nevrac√≠ v≈ædy ƒçist√Ω JSON. `OllamaTextService` pou≈æ√≠v√° fallback chain:

```csharp
1. JsonSerializer.Deserialize<T>(response)           // p≈ô√≠m√Ω parse
2. Regex: extract prvn√≠ {...} nebo [...]              // strip preamble/postamble
3. return default(T)                                 // graceful degradation
```

---

## 8. Prostorov√© vyhled√°v√°n√≠ (PostGIS)

### Koridorov√© filtrov√°n√≠

Umo≈æ≈àuje naj√≠t inzer√°ty pod√©l trasy (nap≈ô√≠klad `≈†t√≠tary ‚Üí Poho≈ôelice` s bufferem 5 km).

```mermaid
flowchart TD
    UI_MAP["Map.razor\nU≈æivatel si vybere start/end\nbuffer v km"] --> BUILD_API

    BUILD_API["POST /api/spatial/build-corridor\n{ startCity, endCity, bufferMeters }"] --> OSRM_CALL

    OSRM_CALL["OSRM router\nGET /route/v1/driving/{lng1,lat1}..."]
    OSRM_CALL --> POLYLINE["Dek√≥duj encoded polyline\n‚Üí List<Coordinate> (WGS84)"]

    POLYLINE --> ST_BUF["PostGIS: ST_Buffer\n(ST_Transform(geom, 5514), bufferM)\n‚Üí Polygon v S-JTSK (EPSG:5514)\n‚Üí ST_Transform zpƒõt do WGS84"]

    ST_BUF --> SAVE_AREA["INSERT INTO spatial_areas\n{ name, geom, area_type='corridor',\nstart_city, end_city, buffer_m }"]

    SAVE_AREA --> SEARCH["POST /api/spatial/search-in-area\n{ areaId }"]

    SEARCH --> INTERSECTS["SELECT listings.*\nFROM listings l\nJOIN spatial_areas a ON a.id = {areaId}\nWHERE ST_Intersects(l.location_point, a.geom)\nAND l.is_active = true"]

    INTERSECTS --> RESULTS["List<ListingSummaryDto>\nbez str√°nkov√°n√≠ (v≈°e v koridoru)"]
```

### Geocoding pipeline

```
1. Scraper GPS (source='scraper')      ‚Üí nejp≈ôesnƒõj≈°√≠, z metadat webu
2. Nominatim geocoding (source='nominatim') ‚Üí OSM datab√°ze, 1.1s rate limit
3. Heuristika: ExtractCityFromLocationText()
   ‚Üí "Znojmo, P≈ô√≠mƒõtick√° 48" ‚Üí "Znojmo"
   ‚Üí "Praha 6 ‚Äì Dejvice" ‚Üí "Praha 6"
```

**Stav:** 1 366 / 1 403 inzer√°t≈Ø geoc√≥dov√°no (97 % pokryt√≠).

### Kl√≠ƒçov√© PostGIS funkce

| Funkce | √öƒçel |
|--------|------|
| `ST_SetSRID(ST_MakePoint(lng, lat), 4326)` | Vytvo≈ôen√≠ bodu z lat/lng (trigger) |
| `ST_Transform(geom, 5514)` | P≈ôevod z WGS84 do S-JTSK (metrick√© CZ) |
| `ST_Buffer(geom, meters)` | Vytvo≈ôen√≠ koridoru/kruhu |
| `ST_Intersects(a, b)` | Test pr≈Øniku (vyu≈æ√≠v√° GIST index) |
| `ST_DWithin(a, b, meters)` | Hled√°n√≠ v polomƒõru |

---

## 9. DB sch√©ma (ERD)

```mermaid
erDiagram
    sources {
        uuid id PK
        text code UK "REMAX, SREALITY, ..."
        text name
        text base_url
        boolean is_active
        text scraper_type
        timestamptz created_at
        timestamptz updated_at
    }

    listings {
        uuid id PK
        uuid source_id FK
        text source_code
        text external_id
        text url UK
        text title
        text description
        text location_text
        text region
        text district
        text municipality
        text property_type "House|Apartment|Land|..."
        text offer_type "Sale|Rent|Auction"
        numeric price
        integer area_built_up
        integer area_land
        integer rooms
        text disposition
        boolean has_kitchen
        text construction_type
        text condition
        boolean is_active
        double latitude
        double longitude
        geometry location_point "EPSG:4326 GIST"
        text geocode_source
        tsvector search_tsv "GIN fulltext"
        vector description_embedding "1536-dim HNSW"
        text smart_tags "JSON [tag1..tag5]"
        jsonb ai_normalized_data
        text price_signal "low|fair|high"
        text price_signal_reason
        timestamptz first_seen_at
        timestamptz last_seen_at
    }

    listing_photos {
        uuid id PK
        uuid listing_id FK
        text original_url
        text stored_url
        integer order_index
        text classification_label
        float classification_confidence
        text photo_description
        text alt_text "WCAG 2.2 AA"
        text classification_feedback "correct|wrong"
        timestamptz created_at
    }

    listing_analyses {
        uuid id PK
        uuid listing_id FK
        text content "text chunku"
        text title
        text source "auto|claude|user"
        vector embedding "768-dim IVFFlat"
        timestamptz created_at
        timestamptz updated_at
    }

    user_listing_state {
        uuid id PK
        uuid user_id
        uuid listing_id FK
        text status "New|Liked|Disliked|ToVisit|Visited"
        text notes
        timestamptz last_updated
    }

    user_listing_photos {
        uuid id PK
        uuid listing_id FK
        text stored_url
        text original_file_name
        bigint file_size_bytes
        timestamptz taken_at
        timestamptz uploaded_at
        text notes
    }

    analysis_jobs {
        uuid id PK
        uuid listing_id FK
        uuid user_id
        text status "Pending|Running|Succeeded|Failed"
        text storage_provider "GoogleDrive|OneDrive|Local"
        text storage_url
        timestamptz requested_at
        timestamptz finished_at
        text error_message
    }

    scrape_runs {
        uuid id PK
        uuid source_id FK
        text source_code
        text status "Running|Succeeded|Failed"
        integer total_seen
        integer total_new
        integer total_updated
        integer total_inactivated
        timestamptz started_at
        timestamptz finished_at
    }

    scrape_jobs {
        uuid id PK
        text[] source_codes
        boolean full_rescan
        text status "Queued|Running|Succeeded|Failed"
        integer progress "0-100"
        integer listings_found
        integer listings_new
        timestamptz created_at
        timestamptz started_at
        timestamptz finished_at
    }

    spatial_areas {
        uuid id PK
        text name
        text area_type "corridor|bbox|polygon|circle"
        geometry geom "EPSG:4326 GIST"
        text start_city
        text end_city
        integer buffer_m
        boolean is_active
        timestamptz created_at
        timestamptz updated_at
    }

    sources ||--o{ listings : "has"
    listings ||--o{ listing_photos : "has"
    listings ||--o{ listing_analyses : "has"
    listings ||--o{ user_listing_state : "has"
    listings ||--o{ user_listing_photos : "has"
    listings ||--o{ analysis_jobs : "has"
    sources ||--o{ scrape_runs : "tracks"
```

### Indexov√° strategie

| Index | Tabulka | Typ | √öƒçel |
|-------|---------|-----|------|
| `idx_listings_active_region_price` | listings | B-tree (partial) | Z√°kladn√≠ filtrov√°n√≠ |
| `idx_listings_search_tsv` | listings | GIN | Plnotextov√© vyhled√°v√°n√≠ |
| `idx_listings_description_embedding_hnsw` | listings | HNSW (m=16, ef_c=64) | S√©mantick√© vyhled√°v√°n√≠ |
| `idx_listings_location_point` | listings | GIST (partial) | Prostorov√© dotazy |
| `idx_listing_analyses_embedding` | listing_analyses | IVFFlat (lists=100) | RAG retrieval |
| `idx_listing_photos_listing_id` | listing_photos | B-tree | JOIN fotky |
| `idx_spatial_areas_geom` | spatial_areas | GIST | ST_Intersects koridory |

---

## 10. API endpoint reference

V≈°echny endpointy jsou na `http://localhost:5001`. Scraping endpointy vy≈æaduj√≠ `X-Api-Key` header.

### Listings

| Metoda | Cesta | Popis |
|--------|-------|-------|
| `POST` | `/api/listings/search` | Str√°nkovan√© filtrov√°n√≠ (JSON body `ListingFilterDto`) |
| `GET` | `/api/listings/{id}` | Detail inzer√°tu + fotky + AI pole |
| `GET` | `/api/listings/export.csv` | Export CSV (UTF-8 BOM, semicolony, max 5 000) |
| `GET` | `/api/listings/my-listings` | Skupiny dle user stavu (ToVisit / Liked / Visited / Disliked) |

### Photos

| Metoda | Cesta | Popis |
|--------|-------|-------|
| `POST` | `/api/photos/bulk-classify` | Vision klasifikace fotek |
| `POST` | `/api/photos/sort-by-category` | P≈ôe≈ôadit `order_index` dle kategorie |
| `POST` | `/api/photos/bulk-alt-text` | Generovat WCAG alt text |
| `PATCH` | `/api/photos/{id}/classification-feedback` | Feedback `correct`/`wrong` |
| `POST` | `/api/photos/bulk-download` | St√°hnout fotky do lok√°ln√≠ho storage |
| `GET` | `/api/photos/stats` | Statistiky sta≈æen√Ωch fotek |
| `GET` | `/api/listings/{id}/inspection-photos` | Fotky z prohl√≠dky (user_listing_photos) |

### Ollama Text

| Metoda | Cesta | Popis |
|--------|-------|-------|
| `POST` | `/api/ollama/bulk-smart-tags` | Smart tagy pro N inzer√°t≈Ø |
| `POST` | `/api/ollama/bulk-normalize` | AI normalizace dat |
| `POST` | `/api/ollama/bulk-price-opinion` | Cenov√Ω sign√°l |
| `POST` | `/api/ollama/detect-duplicates` | Detekce duplik√°t≈Ø (id1, id2) |
| `GET` | `/api/ollama/stats` | Poƒçty zpracovan√Ωch AI pol√≠ |

### RAG

| Metoda | Cesta | Popis |
|--------|-------|-------|
| `POST` | `/api/rag/ask-listing/{id}` | Chat nad konkr√©tn√≠m inzer√°tem |
| `POST` | `/api/rag/ask` | Cross-listing s√©mantick√Ω chat |
| `POST` | `/api/rag/embed/{id}` | Indexovat popis inzer√°tu |
| `POST` | `/api/rag/bulk-embed` | Bulk indexace (limit param) |
| `GET` | `/api/rag/analyses/{id}` | V≈°echny anal√Ωzy inzer√°tu |
| `DELETE` | `/api/rag/analyses/{analysisId}` | Smazat anal√Ωzu |

### Spatial

| Metoda | Cesta | Popis |
|--------|-------|-------|
| `POST` | `/api/spatial/build-corridor` | Vytvo≈ôit koridor (OSRM + ST_Buffer) |
| `POST` | `/api/spatial/search-in-area` | Inzer√°ty v oblasti |
| `GET` | `/api/spatial/areas` | V≈°echny ulo≈æen√© oblasti |
| `POST` | `/api/spatial/bulk-geocode` | Bulk geocoding (Nominatim) |
| `GET` | `/api/spatial/map-points` | GPS body pro Leaflet mapu |

### Katastr

| Metoda | Cesta | Popis |
|--------|-------|-------|
| `POST` | `/api/cadastre/single` | R√öIAN lookup pro jeden inzer√°t |
| `POST` | `/api/cadastre/bulk` | Bulk R√öIAN lookup |
| `GET` | `/api/cadastre/stats` | Statistiky katastr√°ln√≠ch dat |

### Scraping (vy≈æaduje `X-Api-Key`)

| Metoda | Cesta | Popis |
|--------|-------|-------|
| `POST` | `/api/scraping/trigger` | Spustit scraping job |
| `GET` | `/api/scraping/jobs` | Seznam job≈Ø |
| `GET` | `/api/scraping/jobs/{id}` | Detail jobu (progress %) |
| `GET` | `/api/sources` | Seznam zdroj≈Ø |

### Export / AI anal√Ωza

| Metoda | Cesta | Popis |
|--------|-------|-------|
| `POST` | `/api/export/google-drive/{id}` | Export do Google Drive |
| `POST` | `/api/export/onedrive/{id}` | Export do OneDrive |
| `GET` | `/api/listings/{id}/export-content` | Export bal√≠ƒçek (MD + JSON + foto URL) |

### MCP Server (:8002)

| Tool | Read/Write | Popis |
|------|-----------|-------|
| `search_listings` | Read | Hled√°n√≠ inzer√°t≈Ø |
| `get_listing` | Read | Detail + z√°pis z prohl√≠dky + Drive URL |
| `get_analyses` | Read | V≈°echny anal√Ωzy (pln√Ω obsah) |
| `get_inspection_photos` | Read | Fotky z prohl√≠dky |
| `save_analysis` | Write | Ulo≈æit anal√Ωzu + embedding |

---

## 11. Konfigurace a secrets

### Kl√≠ƒçov√© env promƒõnn√© (API)

| Promƒõnn√° | Default | Popis |
|----------|---------|-------|
| `DB_HOST` | `localhost` | Postgres host (docker: `postgres`) |
| `DB_PORT` | `5432` | Postgres port |
| `OLLAMA_BASE_URL` | ‚Äì | Ollama endpoint (`http://host.docker.internal:11434`) |
| `Ollama__VisionModel` | `llama3.2-vision:11b` | Vision model |
| `Embedding__Provider` | `ollama` | `ollama` nebo `openai` |
| `Embedding__VectorDimensions` | `768` | Dimenze vektoru |
| `API_KEY` | `dev-key-change-me` | Kl√≠ƒç pro scraping endpointy |
| `SCRAPER_API_BASE_URL` | `http://localhost:8001` | Python scraper URL |
| `PHOTOS_PUBLIC_BASE_URL` | `http://localhost:5001` | Ve≈ôejn√° URL pro fotky |

### Secrets (./secrets/)

| Soubor | Obsah |
|--------|-------|
| `google-drive-sa.json` | Google Drive service account credentials |
| `google-drive-token.json` | OAuth2 access token (zapisuje callback) |
| `onedrive-token.json` | Microsoft OneDrive OAuth token |

---

## 12. Monitoring a logging

### Serilog (ASP.NET Core API)

```mermaid
flowchart LR
    APP["Aplikaƒçn√≠ k√≥d\nILogger<T>"] --> SERILOG["Serilog pipeline"]
    SERILOG --> ENV{"Environment?"}
    ENV -->|Development| CONSOLE["ColoredConsole\ns SourceContext"]
    ENV -->|Production| JSON["CompactJsonFormatter\nJSON soubory v /app/logs"]
    SERILOG --> HTTP_LOG["UseSerilogRequestLogging()\nHTTP method ¬∑ path ¬∑ status ¬∑ ms"]
```

**Bootstrap logger:** zachyt√≠ chyby p≈ôed inicializac√≠ DI (startup p√°d).

**MinimumLevel overrides:**

| Namespace | √örove≈à |
|-----------|--------|
| Default | `Information` |
| `Microsoft.EntityFrameworkCore` | `Warning` |
| `Microsoft.AspNetCore` | `Warning` |
| `System.Net.Http` | `Warning` |

### Scrape Run monitoring

Ka≈æd√Ω bƒõh scraperu zapisuje do `scrape_runs`:

```sql
SELECT source_code, total_new, total_updated, total_inactivated,
       EXTRACT(EPOCH FROM (finished_at - started_at)) AS duration_sec
FROM re_realestate.v_scrape_run_stats
ORDER BY last_run_at DESC;
```

---

## 13. V√Ωkonnostn√≠ tipy

### pgvector tuning

```sql
-- Vy≈°≈°√≠ p≈ôesnost (produkce ‚Äì velk√© datasety):
CREATE INDEX ... WITH (m = 32, ef_construction = 128);

-- Rychlej≈°√≠ build (v√Ωvoj / mal√© datasety):
CREATE INDEX ... WITH (m = 8, ef_construction = 32);

-- Reindex po hromadn√©m insertu:
REINDEX INDEX CONCURRENTLY idx_listings_description_embedding_hnsw;
```

### Doporuƒçen√© po≈ôad√≠ filtr≈Ø

1. **Klasick√© WHERE** klauzule (region, price, property_type) ‚Äì B-tree indexy
2. **Fulltext** `search_tsv @@ plainto_tsquery(...)` ‚Äì GIN index
3. **Prostorov√©** `ST_Intersects(location_point, corridor_geom)` ‚Äì GIST index
4. **Vektorov√©** `ORDER BY embedding <-> :vec LIMIT K` ‚Äì HNSW/IVFFlat (v≈ædy jako posledn√≠, na nejmen≈°√≠ podmno≈æinƒõ)

### Embedding batch size

- Ollama `nomic-embed-text`: bez rate limitu, ale sekvenƒçn√≠ (ne paraleln√≠ ‚Äì jeden model)
- Doporuƒçen√Ω batch: 50‚Äì100 inzer√°t≈Ø na request do `/api/rag/bulk-embed`

### Docker rebuild after C# changes

```bash
docker compose build --no-cache app api && docker compose up -d --no-deps app api
```

> ‚ö†Ô∏è **Zapomenut√Ω rebuild = star√Ω k√≥d v kontejnerech.** V≈ædy po zmƒõnƒõ C# k√≥du.
