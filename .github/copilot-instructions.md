# GitHub Copilot Instructions ‚Äì RealEstateAggregator

**Project:** Real Estate Aggregator with Semantic Search & AI Analysis  
**Stack:** .NET 10, Blazor Server, PostgreSQL 15 + **PostGIS 3.4** + pgvector, Python FastAPI scrapers, **MCP Tools for Claude Desktop**  
**Last Updated:** 26. √∫nora 2026 (Session 14)

---

## Project Context

Full-stack aplikace pro agregaci realitn√≠ch inzer√°t≈Ø z ƒçesk√Ωch web≈Ø. Aktu√°lnƒõ integruje **12 zdroj≈Ø a 1 236+ aktivn√≠ch inzer√°t≈Ø**. Podporuje s√©mantick√© vyhled√°v√°n√≠ pomoc√≠ pgvector, filtrov√°n√≠ dle typu nemovitosti/nab√≠dky/ceny a AI anal√Ωzu inzer√°t≈Ø.

### Aktivn√≠ scrape≈ôi (12 zdroj≈Ø)
| K√≥d | N√°zev | Soubor |
|---|---|---|
| REMAX | RE/MAX Czech Republic | remax_scraper.py |
| MMR | M&M Reality | mmreality_scraper.py |
| PRODEJMETO | Prodejme.to | prodejmeto_scraper.py |
| SREALITY | Sreality.cz | sreality_scraper.py |
| IDNES | iDnes Reality | idnes_reality_scraper.py |
| CENTURY21 | CENTURY 21 Czech Republic | century21_scraper.py |
| PREMIAREALITY | Premiera Reality | premiareality_scraper.py |
| DELUXREALITY | Delux Reality | deluxreality_scraper.py |
| HVREALITY | HV Reality | hvreality_scraper.py |
| LEXAMO | Lexamo | lexamo_scraper.py |
| ZNOJMOREALITY | Znojmo Reality | znojmoreality_scraper.py |
| NEMZNOJMO | Nemovitosti Znojmo | nemovitostiznojmo_scraper.py |
| REAS | Reas.cz | reas_scraper.py |

## Persistent Rules (Always Apply)

- MudBlazor 9 je primarni UI stack. Nezminuj MudBlazor 7, pokud nejde o historickou poznamku.
- Udrzuj verze stacku konzistentni napric README, QUICK_START, TECHNICAL_DESIGN, API_CONTRACTS, AI_SESSION_SUMMARY.
- Pri zmenach scrapingu aktualizuj souvisejici dokumentaci a instrukce, aby odpovidaly realnemu chovani.
- **Po kazde zmene C# kodu ktera jde do Docker: `docker compose build --no-cache app api && docker compose up -d --no-deps app api`.** Zapomenuty rebuild = stary kod v kontejnerech. VZDY rebuild po zmene kodu.
- **Docker restart policy:** vsechny 4 sluzby (postgres, api, app, scraper) MUSI mit `restart: unless-stopped` v docker-compose.yml.

### Architecture

```
Blazor UI (:5002)
    ‚Üì HTTP
.NET API (:5001)
    ‚Üì EF Core + Npgsql
PostgreSQL (:5432)
    ‚Üë asyncpg
Python Scraper API (:8001)
    ‚Üì httpx + BeautifulSoup
External Real Estate Sites
```

---

## Code Style & Conventions

### C# (.NET)
```csharp
// ‚úÖ USE: Minimal APIs with endpoint groups
app.MapGroup("/api/listings")
   .MapPost("/search", SearchListings);

// ‚úÖ USE: Primary constructors (C# 12)
public sealed class ListingService(IListingRepository repo, ILogger<ListingService> logger)
{
    public async Task<PagedResult> SearchAsync(ListingFilter filter)
    {
        // Implementation
    }
}

// ‚úÖ USE: Record types for DTOs
public record ListingSummaryDto(
    Guid Id,
    string Title,
    decimal? Price,
    string LocationText
);

// ‚ùå AVOID: Controller classes (use Minimal APIs instead)
// ‚ùå AVOID: AutoMapper (use manual mapping)
```

### Database
```csharp
// ‚úÖ USE: Snake_case via EFCore.NamingConventions
options.UseSnakeCaseNamingConvention();

// ‚úÖ USE: Enum converters s switch expression (NE Enum.Parse ‚Äì nefunguje v EF Core expression trees)
// ‚ö†Ô∏è KRITICK√â: DB ukl√°d√° anglicky ("House", "Apartment", "Sale", "Rent")
// ‚ö†Ô∏è NESM√ç≈† pou≈æ√≠t ƒçesky ("D≈Øm", "Byt") ‚Äì zp≈Øsobuje 0 v√Ωsledk≈Ø p≈ôi filtrov√°n√≠!
modelBuilder.Entity<Listing>()
    .Property(l => l.PropertyType)
    .HasConversion(
        v => v.ToString(),  // z√°pis: "House", "Apartment", ...
        v => v == "House" ? PropertyType.House
           : v == "Apartment" ? PropertyType.Apartment
           : v == "Land" ? PropertyType.Land
           : v == "Cottage" ? PropertyType.Cottage
           : v == "Commercial" ? PropertyType.Commercial
           : v == "Industrial" ? PropertyType.Industrial
           : v == "Garage" ? PropertyType.Garage
           : PropertyType.Other);

// OfferType analogicky:
//   v => v.ToString()  ‚Üí  "Sale", "Rent", "Auction"
//   v == "Rent" ? OfferType.Rent : v == "Auction" ? OfferType.Auction : OfferType.Sale

// Table: re_realestate.listings
// Columns: id, source_id, source_code, external_id, title, property_type, offer_type, price...
```

### Python (Scraper)
```python
# ‚úÖ USE: Async/await everywhere
async def scrape(self, max_pages: int = 5) -> int:
    async with httpx.AsyncClient() as client:
        # Implementation

# ‚úÖ USE: Type hints
def _parse_detail_page(self, html: str, item: Dict[str, Any]) -> Dict[str, Any]:
    # Implementation

# ‚úÖ USE: asyncpg for database
db_manager = get_db_manager()
await db_manager.upsert_listing(listing_data)

# ‚ùå AVOID: Blocking I/O (use async variants)
```

### Blazor
```razor
@* ‚úÖ USE: MudBlazor components with explicit type parameters *@
<MudChip T="string" Size="Size.Small">@item.SourceName</MudChip>
<MudCarousel TData="object" Style="height:400px;">
    @* Content *@
</MudCarousel>

@* ‚úÖ USE: Dependency injection *@
@inject NavigationManager Navigation
@inject ISnackbar Snackbar
@inject IListingService ListingService

@* ‚úÖ USE: Error handling with user feedback *@
try {
    await ListingService.DoSomethingAsync();
    Snackbar.Add("Success!", Severity.Success);
} catch (Exception ex) {
    Snackbar.Add($"Error: {ex.Message}", Severity.Error);
}
```

---

## Common Tasks

### Adding a New API Endpoint

1. **Create DTO in Contracts/**
```csharp
// src/RealEstate.Api/Contracts/Listings/ListingFilterDto.cs
public record ListingFilterDto(
    string? SearchQuery,
    PropertyType? PropertyType,
    int Page = 1,
    int PageSize = 20
);
```

2. **Add endpoint in Endpoints/**
```csharp
// src/RealEstate.Api/Endpoints/ListingEndpoints.cs
group.MapPost("/advanced-search", AdvancedSearch)
    .WithName("AdvancedSearch");

private static async Task<Ok<PagedResultDto<ListingSummaryDto>>> AdvancedSearch(
    [FromBody] ListingFilterDto filter,
    [FromServices] IListingService service,
    CancellationToken ct)
{
    var result = await service.AdvancedSearchAsync(filter, ct);
    return TypedResults.Ok(result);
}
```

3. **Implement in Service**
```csharp
// src/RealEstate.Api/Services/ListingService.cs
public async Task<PagedResult<ListingSummaryDto>> AdvancedSearchAsync(
    ListingFilterDto filter, 
    CancellationToken ct)
{
    // EF Core query logic
}
```

### Adding Database Migration

```bash
# Create migration
dotnet ef migrations add AddNewFeature --project src/RealEstate.Infrastructure

# Apply migration
dotnet ef database update --project src/RealEstate.Api
```

### Creating a New Scraper

1. **Copy remax_scraper.py template** (nebo jin√Ω hotov√Ω scraper jako vzor)
```python
# scraper/core/scrapers/novyscraper_scraper.py
class NovyScraperScraper:
    BASE_URL = "https://novyscraper.cz"
    SOURCE_CODE = "NOVYSCRAPER"
    
    async def run(self, full_rescan: bool = False) -> int:
        max_pages = 100 if full_rescan else 5
        return await self.scrape(max_pages)
    
    def _parse_list_page(self, html: str) -> List[Dict[str, Any]]:
        # Regex-based selectors (robust)
        
    def _parse_detail_page(self, html: str, item: Dict) -> Dict[str, Any]:
        # Extract: title, price, location, photos (max 20), area
        # Mapuj property_type a offer_type pomoc√≠ property_type_map/offer_type_map z database.py
```

2. **Add to runner.py**
```python
from ..core.scrapers.novyscraper_scraper import NovyScraperScraper

if "NOVYSCRAPER" in source_codes:
    scraper = NovyScraperScraper()
    count = await scraper.run(full_rescan=request.full_rescan)
```

3. **Seed database**
```sql
INSERT INTO re_realestate.sources (id, code, name, base_url, is_active)
VALUES (gen_random_uuid(), 'NOVYSCRAPER', 'Nov√Ω Scraper', 'https://novyscraper.cz', true);
```

---

## Important Patterns

### Enum Mapping (Czech ‚Üî English)

```python
# Database stores English. Scraper mapuje z ƒçe≈°tiny:
property_type_map = {
    "D≈Øm": "House", "Byt": "Apartment", "Pozemek": "Land",
    "Chata": "Cottage", "Komerƒçn√≠": "Commercial", "Ostatn√≠": "Other",
}

offer_type_map = {
    "Prodej": "Sale",
    "Pron√°jem": "Rent",
    "Dra≈æba": "Auction",   # ‚Üê SReality category_type_cb=3
}
```

```csharp
// OfferType enum: Sale, Rent, Auction
// DB ukl√°d√°: "Sale", "Rent", "Auction"
// HasConversion: Enum.Parse ‚Üí NEPOU≈Ω√çVAT, pou≈æij switch expression:
// v == "Rent" ? OfferType.Rent : v == "Auction" ? OfferType.Auction : OfferType.Sale
```

### SReality URL pravidla (KRITICK√â ‚Äì nerozb√≠jej!)

URL se builduje v `_build_detail_url()` ve `sreality_scraper.py`:
- Form√°t: `/detail/{cat_type_slug}/{cat_main_slug}/{cat_sub_slug}/{locality}/{hash_id}`
- `cat_type`: 1=prodej, 2=pronajem, **3=drazba**
- `_merge_detail()` V≈ΩDY refreshuje URL z detail API SEO ‚Äì nevynech√°vej to vol√°n√≠
- `_CAT_SUB_SLUG_OVERRIDES = {2: {40: "na-klic"}}` ‚Äì domy na kl√≠ƒç maj√≠ jin√Ω slug ne≈æ SReality default
- Dra≈æby maj√≠ kr√°tkou ≈æivotnost ‚Üí URL vr√°t√≠ 404 po skonƒçen√≠ dra≈æby. To je **expected chov√°n√≠**, ne bug
- Expired inzer√°ty jsou deaktivov√°ny (`is_active=false`) automaticky p≈ôi p≈ô√≠≈°t√≠m `full_rescan` p≈ôes `deactivate_unseen_listings()`

### Upsert Pattern (Deduplication)

```python
# scraper/core/database.py
async def upsert_listing(self, listing_data: Dict[str, Any]) -> UUID:
    # Check if exists by (source_id, external_id)
    existing = await conn.fetchrow(
        "SELECT id FROM re_realestate.listings WHERE source_id = $1 AND external_id = $2",
        source_id, external_id
    )
    
    if existing:
        # UPDATE existing
        await conn.execute("UPDATE re_realestate.listings SET ... WHERE id = $1")
    else:
        # INSERT new
        listing_id = uuid4()
        await conn.execute("INSERT INTO re_realestate.listings (...) VALUES (...)")
```

### AI Anal√Ωza ‚Äì template syst√©m

≈†ablony pro AI instrukce jsou **runtime `.md` soubory** ‚Äì editovateln√© bez recompilace:

```
src/RealEstate.Api/Templates/
  ai_instrukce_existing.md   ‚Üê existuj√≠c√≠ nemovitosti
  ai_instrukce_newbuild.md   ‚Üê novostavby
```

`ListingExportContentBuilder.BuildAiInstructions()` naƒçte spr√°vnou ≈°ablonu dle `IsNewBuild()` a interpoluje `{{PLACEHOLDERS}}`:
- `{{LOCATION}}`, `{{PROPERTY_TYPE}}`, `{{OFFER_TYPE}}`, `{{PRICE}}`, `{{PRICE_NOTE}}`
- `{{AREA}}`, `{{ROOMS_LINE}}`, `{{CONSTRUCTION_TYPE_LINE}}`, `{{CONDITION_LINE}}`
- `{{SOURCE_NAME}}`, `{{SOURCE_CODE}}`, `{{URL}}`
- `{{PHOTO_LINKS_SECTION}}` ‚Äì inline fotky pro AI chat
- `{{DRIVE_FOLDER_SECTION}}` ‚Äì odkaz na cloud slo≈æku

`IsNewBuild()` ‚Äì keywords: `novostavb`, `ve v√Ωstavb`, `pod kl√≠ƒç`, `developersk√Ω projekt`, `dokonƒçen√≠ 202x`, `condition=Nov√Ω/Nov√°`

‚ö†Ô∏è Po zmƒõnƒõ ≈°ablony v Docker ‚Äì `docker cp` staƒç√≠ pro jednor√°zovou zmƒõnu, rebuild api pro trvalou:
```bash
# Jednor√°zov√° zmƒõna (do restartu):
docker cp src/RealEstate.Api/Templates/ai_instrukce_existing.md realestate-api:/app/Templates/
# Trval√° zmƒõna:
docker compose build --no-cache api && docker compose up -d --no-deps api
```

### MCP Tools for AI Analysis

**Model Context Protocol** ‚Äì integrace s Claude Desktop pro p≈ô√≠mou spr√°vu anal√Ωz.

**Um√≠stƒõn√≠:** `mcp/server.py` ‚Äì custom MCP server bƒõ≈æ√≠c√≠ na `http://localhost:5001/api/*`

**Konfigurace:** `~/Library/Application Support/Claude/claude_desktop_config.json`
```json
{
  "mcpServers": {
    "realestate": {
      "command": "python3",
      "args": ["/Users/petrsramek/Projects/RealEstateAggregator/mcp/server.py"],
      "env": {
        "REALESTATE_API_URL": "http://localhost:5001"
      }
    }
  }
}
```

**Workflow pro Claude Desktop:**
```python
# 1. Naj√≠t inzer√°ty
search_listings(query="Znojmo d≈Øm 3M")

# 2. Naƒç√≠st KOMPLETN√ç detail (+ Z√ÅPIS Z PROHL√çDKY!)
get_listing(listing_id="14fe1165...")
# Vr√°t√≠: cena, plocha, GPS, popis, Drive URL,
#        üìã Z√ÅPIS Z PROHL√çDKY (pozn√°mky z osobn√≠ n√°v≈°tƒõvy),
#        üì∏ fotky z inzer√°tu + üì∑ fotky z prohl√≠dky

# 3. P≈ôeƒç√≠st v≈°echny existuj√≠c√≠ anal√Ωzy
get_analyses(listing_id="14fe1165...")
# Vr√°t√≠: historii v≈°ech anal√Ωz (pln√Ω obsah bez zkr√°cen√≠)

# 4. Ulo≈æit NOVOU anal√Ωzu
save_analysis(
    listing_id="14fe1165...",
    content="# Anal√Ωza...",
    title="Anal√Ωza z prohl√≠dky 26.2.2026",
    source="claude"  # automaticky tagged
)
# Anal√Ωza se ulo≈æ√≠ do DB + vygeneruje pgvector embedding ‚Üí prohled√°vateln√° p≈ôes RAG
```

**Dostupn√© MCP Tools:**
| Tool | Popis | Read/Write |
|------|-------|------------|
| `search_listings` | Naj√≠t inzer√°ty dle query, filtru | ‚úÖ Read |
| `get_listing` | Kompletn√≠ detail + Z√ÅPIS Z PROHL√çDKY | ‚úÖ Read |
| `get_analyses` | V≈°echny ulo≈æen√© anal√Ωzy (pln√Ω obsah) | ‚úÖ Read |
| `get_inspection_photos` | Vlastn√≠ fotky z prohl√≠dky | ‚úÖ Read |
| `save_analysis` | Ulo≈æit novou anal√Ωzu + embedding | ‚úçÔ∏è Write |

**Kl√≠ƒçov√© vlastnosti:**
- `source="claude"` ‚Äì ka≈æd√° anal√Ωza je automaticky oznaƒçen√° zdrojem
- **Pln√Ω obsah bez zkr√°cen√≠** ‚Äì `get_analyses` vrac√≠ kompletn√≠ text anal√Ωz
- **Z√ÅPIS Z PROHL√çDKY je v get_listing** ‚Äì automaticky souƒç√°st√≠ dat, ne samostatn√Ω call
- **Embedding auto-generuje** ‚Äì ka≈æd√° ulo≈æen√° anal√Ωza dostane pgvector embedding pro RAG
- **Drive URL** ‚Äì `get_listing` vrac√≠ p≈ô√≠m√Ω odkaz na Google Drive slo≈æku s exporty

‚ö†Ô∏è **Restart Claude Desktop** po zmƒõn√°ch v `mcp/server.py` nebo config!

### Photo Synchronization

```python
async def _upsert_photos(self, conn, listing_id: UUID, photo_urls: List[str]) -> None:
    # ‚ö†Ô∏è MUST run in transaction for atomicity
    async with conn.transaction():
        # Delete old photos
        await conn.execute("DELETE FROM re_realestate.listing_photos WHERE listing_id = $1")
        
        # Insert new photos
        for idx, photo_url in enumerate(photo_urls[:20]):
            await conn.execute("INSERT INTO re_realestate.listing_photos (...)")
```

---

## Configuration

### Connection Strings

**Local development:**
```json
// appsettings.Development.json
{
  "ConnectionStrings": {
    "RealEstate": "Host=localhost;Port=5432;Database=realestate_dev;Username=postgres;Password=dev"
  },
  "ScraperApi": {
    "BaseUrl": "http://localhost:8001"
  }
}
```

**Docker deployment:**
```json
// appsettings.json (or environment variables)
{
  "ConnectionStrings": {
    "RealEstate": "Host=postgres;Port=5432;Database=realestate_dev;..."
  },
  "ScraperApi": {
    "BaseUrl": "http://scraper:8001"
  }
}
```

### Python Config

```yaml
# scraper/config/settings.yaml
database:
  host: localhost  # or "postgres" in Docker
  port: 5432
  database: realestate_dev
  user: postgres
  password: dev
```

---

## Testing

### Manual API Testing

```bash
# Start services
docker-compose up -d postgres
dotnet run --project src/RealEstate.Api --urls "http://localhost:5001"
dotnet run --project src/RealEstate.App --urls "http://localhost:5002"

# Scraper vy≈æaduje virtualenv (python3 nen√≠ v PATH, pou≈æij venv):
cd scraper && .venv/bin/python run_api.py
# Pokud venv neexistuje:
# python3 -m venv scraper/.venv && source scraper/.venv/bin/activate
# pip install -r scraper/requirements.txt

# Test endpoints
curl http://localhost:5001/api/sources
curl -X POST http://localhost:5001/api/listings/search \
  -H "Content-Type: application/json" \
  -d '{"page":1,"pageSize":10}'

# Trigger scraping (p≈ôes .NET API ‚Üí Python Scraper API)
# ‚ö†Ô∏è Scraping endpointy jsou chr√°nƒõny API kl√≠ƒçem (X-Api-Key header)
curl -X POST http://localhost:5001/api/scraping/trigger \
  -H "Content-Type: application/json" \
  -H "X-Api-Key: dev-key-change-me" \
  -d '{"sourceCodes":["REMAX"],"fullRescan":false}'

# Nebo p≈ô√≠mo na Python Scraper API:
curl -X POST http://localhost:8001/v1/scrape/run \
  -H "Content-Type: application/json" \
  -d '{"source_codes":["REMAX"],"full_rescan":false}'
```

### Database Queries

```bash
# Connect to database
docker exec -it realestate-db psql -U postgres -d realestate_dev

# Check data
SELECT COUNT(*) FROM re_realestate.listings;
SELECT code, name, is_active FROM re_realestate.sources;
SELECT l.title, l.price, s.name FROM re_realestate.listings l JOIN re_realestate.sources s ON l.source_id = s.id LIMIT 5;
```

---

## Known Limitations & TODOs

### ‚úÖ Dokonƒçeno v Session 4 (2026-02-23)
- [x] **Security** ‚Äì API key middleware na scraping endpointech (`X-Api-Key`)
- [x] **CORS** ‚Äì `AddCors()` + `UseCors()` v Program.cs
- [x] **Health endpoint** ‚Äì `/health` + Docker healthcheck
- [x] **Filtered Include** ‚Äì UserStates N+1 odstranƒõno
- [x] **tsvector fulltext** ‚Äì GIN index nam√≠sto ILIKE
- [x] **Retry logic** ‚Äì tenacity `@http_retry` na 11 scraperech
- [x] **CancellationToken** ‚Äì HTTP vol√°n√≠ v Listings.razor s CT
- [x] **SourceDto** ‚Äì extrahov√°no do `Models/SourceDto.cs`
- [x] **39 unit test≈Ø** ‚Äì enum, NormalizeStatus, DTOs
- [x] **Tiebreaker** ‚Äì `.ThenBy(x => x.Id)` pro deterministick√© str√°nkov√°n√≠
- [x] **user_listing_photos** tabulka v init-db.sql

### ‚úÖ Dokonƒçeno v Session 5 (2026-02-24)
- [x] **Docker restart policy** ‚Äì `restart: unless-stopped` na v≈°ech 4 slu≈æb√°ch v docker-compose.yml
- [x] **OfferType.Auction** ‚Äì p≈ôid√°n do enum, DbContext HasConversion, Listings.razor, ListingDetail.razor, database.py offer_type_map
- [x] **Dra≈æba URL** ‚Äì SReality `cat_type=3` ‚Üí slug `drazba`; `_build_detail_url()` generuje spr√°vn√© URL
- [x] **deactivate_unseen_listings()** ‚Äì automatick√° deaktivace expired inzer√°t≈Ø po full_rescan v runner.py
- [x] **Filter state persistence** ‚Äì `ListingsPageState` + `ProtectedSessionStorage` (bylo ji≈æ v Session 4 k√≥du, Docker image byl stary ‚Äì fixed rebuildeem)
- [x] **5 expired SReality inzer√°t≈Ø** deaktivov√°no p≈ô√≠mo v DB; 5 dra≈æeb retroaktivnƒõ opraveno na `offer_type='Auction'`
- [x] **MSBuild CS2021 glob fix** ‚Äì `EnableDefaultCompileItems=false` + explicitn√≠ Compile items v `Infrastructure.csproj`, `Api.csproj`, `Background.csproj`; Docker image api/scraper/app √∫spƒõ≈°nƒõ rebuild

### ‚úÖ Dokonƒçeno v Session 6 (2026-02-25)
- [x] **AI ≈°ablony externalizov√°ny** ‚Äì `BuildAiInstructions()` naƒç√≠t√° `.md` soubory z `src/RealEstate.Api/Templates/` m√≠sto hardcoded string≈Ø; editovateln√© bez recompilace
- [x] **GoogleDriveExportService.cs** ‚Äì odstranƒõno ~400 ≈ô√°dk≈Ø dead code (priv√°tn√≠ kopie BuildAiInstructions, BuildInfoMarkdown, BuildDataJson, IsNewBuild, SanitizeName); v≈°e p≈ôesunuto do sd√≠len√©ho `ListingExportContentBuilder`
- [x] **ai_instrukce_existing.md** ‚Äì kompletn√≠ p≈ôepis: tabulky (üí∞ finanƒçn√≠ kalkulace, üîß technick√Ω stav, üìä yield), emoji hierarchie (üî¥üü°üü¢‚úÖ‚ö†Ô∏è), sekce ‚ÄûCo bylo renovov√°no", emoji VERDIKT, prohl√≠dka TABLE
- [x] **ai_instrukce_newbuild.md** ‚Äì kompletn√≠ p≈ôepis: sekce ‚ÄûKl√≠ƒçov√© technologie a vybaven√≠" m√≠sto renovace, tabulka technologi√≠ (Tƒå, rekuperace, smart home), NEPI≈† o rekonstrukci
- [x] **Unit testy 39 ‚Üí 111** (+72 test≈Ø): `ExportBuilderTests.cs` (IsNewBuild 14 variant, SanitizeName, BuildDataJson, PhotoLinks, PageGuard), `RagServiceTests.cs` (CosineSimilarity 8 variant, BuildListingText 11 variant), `UnitTest1.cs` (+Auction enum, +Auction jako invalid user status)

### ‚úÖ Dokonƒçeno v Session 7 (2026-02-26)
- [x] **PostGIS 3.4 + pgvector ARM64** ‚Äì nativn√≠ Docker image `postgis/postgis:15-3.4` s `platform: linux/arm64/v8` (bez Rosetta emulace); migrace `scripts/migrate_postgis.sql` p≈ôid√°v√° geometrick√© sloupce + spatial_areas tabulku
- [x] **ƒå√öZK/RUIAN integrace** ‚Äì `listing_cadastre_data` tabulka (`scripts/migrate_cadastre.sql`), `ruian_service.py`, 3 RUIAN endpointy na scraper API (`/v1/ruian/single`, `/v1/ruian/bulk`, `/v1/ruian/stats`), `CadastreService.cs` + `ICadastreService` (.NET), 4 endpointy `/api/cadastre/...`
- [x] **KN v detailu inzer√°tu** ‚Äì `ListingDetail.razor`: sekce ‚ÄûKatastr nemovitost√≠", tlaƒç√≠tko ‚ÄûOtev≈ô√≠t v KN" (nahl√≠≈æen√≠.cuzk.cz deep link `?typeCode=adresniMisto&id={ruianKod}`), tlaƒç√≠tko ‚ÄûNaj√≠t p≈ô√≠m√Ω odkaz (RUIAN)"
- [x] **KN checklist v AI ≈°ablon√°ch** ‚Äì tabulka ‚ÄûCo ovƒõ≈ôit v katastru nemovitost√≠" (z√°stavn√≠ pr√°va, vƒõcn√° b≈ôemena, v√Ωmƒõra, druh pozemku, p≈ô√≠stupov√° cesta) v `ai_instrukce_existing.md` i `ai_instrukce_newbuild.md`
- [x] **Bug fix: DatabaseManager.acquire()** ‚Äì opraveno neexistuj√≠c√≠ `get_connection()` ‚Üí `async with db_manager.acquire() as conn:` v `ruian_service.py` a `main.py`
- [x] **Bug fix: spatial_areas trigger** ‚Äì `CREATE OR REPLACE FUNCTION update_updated_at_column()` p≈ôid√°no do `migrate_postgis.sql` (funkce chybƒõla p≈ôi prvn√≠m bƒõhu mimo init-db.sql)
- [x] **ARM64 collation fix** ‚Äì `ALTER DATABASE realestate_dev REFRESH COLLATION VERSION` po p≈ôechodu na ARM64 postgres image
- [x] **Unit testy 111 ‚Üí 141** (+30 test≈Ø): `CadastreTests.cs` ‚Äì `PreferMunicipality` (10 variant p≈ôes reflection), `ListingCadastreData` defaults, `ListingCadastreDto` record equality, `BulkRuianResultDto`, `SaveCadastreDataRequest`, RUIAN URL form√°t (3 InlineData), `RuianFindUrl` konstanta p≈ôes reflection
### ‚úÖ Dokonƒçeno v Session 19 (2026-02-27)
- [x] **KN OCR screenshot** ‚Äì `POST /api/cadastre/listings/{id}/ocr-screenshot` (multipart `IFormFile`); `CadastreService.OcrScreenshotAsync()` vol√° Ollama Vision `llama3.2-vision:11b` s podrobn√Ωm KN promptem; parsuje `KnOcrData` (parcel_number, lv_number, land_area_m2, land_type, municipality, encumbrances[]); upsertuje `ListingCadastreData` s `FetchStatus="ocr"`; `CadastreOcrResultDto` vrac√≠ data + raw JSON
- [x] **kn-ocr.js** ‚Äì clipboard paste (`Ctrl+V`) + drag&drop na drop-z√≥nu ‚Üí `[JSInvokable] ReceivePastedImageAsync(base64, mimeType)` v Blazor; `knOcr.init(dotNetRef, elementId)` + `knOcr.dispose()`; script tag v `App.razor`
- [x] **KN OCR UI v ListingDetail.razor** ‚Äì drop-z√≥na `kn-ocr-dropzone` s drag feedback, `MudFileUpload` tlaƒç√≠tko, preview obr√°zku, tabulka v√Ωsledk≈Ø (parceln√≠ ƒç., LV, v√Ωmƒõra, druh, vlastn√≠k), seznam bretmen (`ParseEncumbrances()` List-based), Snackbar feedback, cleanup v Dispose
- [x] **bulk-classify-inspection endpoint** ‚Äì `POST /api/photos/bulk-classify-inspection?batchSize=N&listingId=X` ‚Äì Vision klasifikace fotografi√≠ z prohl√≠dky (`user_listing_photos`) pro konkr√©tn√≠ inzer√°t
- [x] **Bulk-normalize progress** ‚Äì background job normalizoval st√°vaj√≠c√≠ inzer√°ty; stav: **249/1416** (~17 %) k datu commitu; job se d√° znovu spustit: `curl -X POST "http://localhost:5001/api/ollama/bulk-normalize?batchSize=50"`
### ‚úÖ Dokonƒçeno v Session 8 (2026-02-27)
- [x] **APScheduler napl√°novan√Ω scraping** ‚Äì `scraper/api/main.py`: `AsyncIOScheduler`, `daily_scrape` (3:00 dennƒõ) + `weekly_full_rescan` (nedƒõle 2:00); 5 endpoint≈Ø `/v1/schedule/jobs|trigger-now|pause|resume|cron`; `settings.yaml` scheduler sekce
- [x] **Fine-tuning guide** ‚Äì `fine-tuning/` adres√°≈ô: `README.md` (Unsloth+QLoRA+SFTTrainer workflow), `finetune_unsloth.py`, `prepare_dataset.py`, `export_to_ollama.sh`, `requirements.txt`
- [x] **REAS scraper oprava** ‚Äì REAS.cz filtroval 100% v√Ωsledk≈Ø na geo filtru; opraveno URL filtrem `jihomoravsky-kraj/cena-do-10-milionu` (141 dom≈Ø, ~15 str√°n); `locality_hint="Jihomoravsk√Ω kraj"` pro subobce; guard count>500 pro nefunkƒçn√≠ segmenty; logo `REAS.svg` p≈ôid√°no
- [x] **Scraper anal√Ωza** ‚Äì ZNOJMOREALITY (5), DELUXREALITY (5), LEXAMO (4): ovƒõ≈ôeno ≈æivƒõ, scrapers funguj√≠ spr√°vnƒõ; weby jsou mal√© lok√°ln√≠ realitky s omezen√Ωm portfoliem (max 7|10|8 inz. celkem)

### ‚úÖ Dokonƒçeno v Session 9 (2026-02-26)
- [x] **Bulk geocoding endpoint** ‚Äì `POST /api/spatial/bulk-geocode?batchSize=N`; EF Core LINQ SELECT + `ExecuteSqlRawAsync` UPDATE; Nominatim 1.1s rate limit; `ExtractCityFromLocationText()` heuristika (ƒç√°rka, ƒç√≠slo pattern); v√Ωsledek: 748/1403 inzer√°t≈Ø geocodov√°no (728 via Nominatim, 20 ze scraperu ‚Üí 53% GPS pokryt√≠, 741 bod≈Ø na mapƒõ)
- [x] **Prostorov√© filtrov√°n√≠ kompletn√≠** ‚Äì `SpatialService.cs`: `BuildCorridorAsync` (OSRM + `ST_Buffer` EPSG:5514), `SearchInAreaAsync` (`ST_Intersects`), `GetAllMapPointsAsync`; `Map.razor`: koridor UI (start/end/buffer/OSRM toggle/save), barevn√© markery dle typu/nab√≠dky, Leaflet popup (foto+cena+link), GPS coverage panel s one-click geocodingem; `leaflet-interop.js`: init/setMarkers/drawCorridor/clearCorridor/fitMarkers/destroy
- [x] **Saved areas panel** ‚Äì Map.razor zobrazuje ulo≈æen√© koridory jako kliknuteln√© chipy; klik napln√≠ formul√°≈ô a znovu postav√≠ koridor p≈ôes API; `LoadSavedAreasAsync` + `LoadSavedAreaAsync` metody
- [x] **Kontejnerizace Blazor App** ‚Äì `realestate-app` Docker kontejner bƒõ≈æ√≠ v docker-compose.yml (port 5002, healthy) ‚Üí TODO splnƒõno

### ‚úÖ Dokonƒçeno v Session 11 (2026-02-26)
- [x] **Python scraper unit testy (83/83)** ‚Äì `scraper/tests/test_parsers.py`: ProdejmeToScraper (_parse_price 5√ó, _parse_area 5√ó, _normalize_offer_type 6√ó, _infer_property_type 9√ó), RemaxScraper mock HTML (_parse_list_page 5√ó, _parse_detail_page 6√ó), ReasScraper (_extract_ads_list 5√ó, _parse_description 3√ó, PROPERTY_TYPE_MAP 8√ó), ZnojmoRealityScraper (_parse_listing 4√ó, _extract_price_from_context 2√ó); `scraper/tests/test_filters.py`: FilterManager quality filtry (6√ó), geo filtr (5√ó), cenov√© limity House (4√ó) + Land (2√ó), kombinovan√© (3√ó), default config (4√ó); `scraper/pytest.ini` + `scraper/tests/__init__.py`

### ‚úÖ Dokonƒçeno v Session 10 (2026-02-26)
- [x] **Geocoding 97%** ‚Äì 7 batch√≠ ‚Üí 1366/1403 geocodov√°no (1346 via Nominatim, 20 ze scraperu); 32 zb√Ωvaj√≠c√≠ch nelze geoc√≥dovat (≈°patn√© lokality)
- [x] **UserStatus filtr v UI** ‚Äì `MudSelect "M≈Øj stav"` v Listings.razor filtru; quick filtry ‚ù§Ô∏è Obl√≠ben√© + üöó K n√°v≈°tƒõvƒõ; `ListingsPageState` roz≈°√≠ren o `UserStatus`; SessionStorage persist
- [x] **Export CSV** ‚Äì `GET /api/listings/export.csv`; `IListingService.ExportCsvAsync` + `ListingService` implementace (pageSize=5000); UTF-8 BOM (Excel), semicolony, ƒçesky; MudIconButton v toolbaru; `BuildCsvExportUrl()` z `Http.BaseAddress`
- [x] **REAS full_rescan** ‚Äì job √∫spƒõ≈°n√Ω (20 inzer√°t≈Ø = spr√°vnƒõ, JMK lok√°ln√≠ filtr)
- [x] **Photo download pipeline** ‚Äì `PhotoDownloadService.cs` + `IPhotoDownloadService`; `POST /api/photos/bulk-download?batchSize=N` (1-200); `GET /api/photos/stats`; ukl√°d√° do `wwwroot/uploads/listings/{id}/photos/`, `stored_url` = `{PHOTOS_PUBLIC_BASE_URL}/uploads/...`; `uploads_data` Docker volume; ~365ms/fotka; 53/53 testovac√≠ batche ‚úì
- [x] **Photo download UI panel** ‚Äì Map.razor: panel pod GPS (celkem/sta≈æeno/%), tlaƒç√≠tko `St√°hnout 100 fotek` ‚Üí bulk-download batch; `LoadPhotoStatsAsync()` v `OnAfterRenderAsync`

### High Priority (zb√Ωv√°)
- [x] Photo download pipeline ‚Äì original_url ‚Üí stored_url (S3/local) ‚úÖ (local uploads_data volume + PhotoDownloadService)
- [x] Kontejnerizace Blazor App ‚Äì `realestate-app` Docker kontejner hotov ‚úÖ
- [x] Prostorov√© filtrov√°n√≠ ‚Äì `ST_Buffer` koridor (PostGIS) + Leaflet mapa + bulk geocoding ‚úÖ

### Scraper kvalita
- [x] ZNOJMOREALITY/DELUXREALITY/LEXAMO ‚Äì ovƒõ≈ôeno: n√≠zk√© poƒçty = mal√© lok√°ln√≠ realitky se skuteƒçnƒõ omezen√Ωm portfoliem, ne chyba scraperu ‚úÖ
- [x] REAS ‚Äì opraveno: `jihomoravsky-kraj/cena-do-10-milionu` URL filtr + `locality_hint` pro subobce + guard (count > 500 = skip) ‚úÖ
  - Pouze `domy` (count=141) funguje s JMK lok√°ln√≠m filtrem + cenov√Ωm stropem
  - `pozemky/komerci/ostatni` s lok√°ln√≠m filtrem vr√°t√≠ count=5124 (= cel√° ƒåR) ‚Äì odebr√°no z CATEGORIES
  - `MAX_EXPECTED_CATEGORY_COUNT = 500` guard v `_scrape_category` chr√°n√≠ p≈ôed p≈ôet√≠≈æen√≠m
  - Logo `REAS.svg` sta≈æeno a p≈ôid√°no do Listings.razor + Home.razor
- [ ] Playwright fallback ‚Äì pro JS-heavy weby

### Medium Priority
- [x] Semantic search ‚Äì RAG service s pgvector (Ollama `nomic-embed-text` 768D, OpenAI 1536D), `FindSimilarAsync` p≈ôes `embedding <->` L2 distance ‚úÖ
- [x] Analysis jobs ‚Äì `AnalysisService` + `RagService.SaveAnalysisAsync` + `BulkEmbedDescriptionsAsync` ‚úÖ
- [ ] User listing states ‚Äì ulo≈æit/archivovat/kontakt tracking (z√°klad hotov, roz≈°√≠≈ôen√≠ zb√Ωv√°)
- [x] **Moje inzer√°ty** ‚Äì `GET /api/listings/my-listings` + `MyListings.razor` (/my-listings): karty seskupen√© dle stavu (K n√°v≈°tƒõvƒõ/Zaj√≠mav√©/Nav≈°t√≠veno/Nezaj√≠mav√©), souhrn ƒçip≈Ø s poƒçty, pr√°zdn√Ω stav, ikona pozn√°mek, NavMenu entry ‚úÖ
- [x] Background scheduled scraping ‚Äì APScheduler `AsyncIOScheduler` v `scraper/api/main.py`, cron 3:00 dennƒõ + nedƒõle 2:00 ‚úÖ

### Low Priority
- [x] **Unit testy scraper** ‚Äì pytest 83/83 zelen√Ωch; `scraper/tests/test_parsers.py` (ProdejmeToScraper, RemaxScraper, ReasScraper, ZnojmoRealityScraper) + `scraper/tests/test_filters.py` (FilterManager geo/quality/price); `scraper/pytest.ini` ‚úÖ
- [x] **Monitoring ‚Äì Serilog structured logging** ‚Äì `Serilog.AspNetCore` 9 + `CompactJsonFormatter` + Enrichers (Environment/Process/Thread); bootstrap logger; `UseSerilogRequestLogging()` (HTTP metoda/path/status/ƒças); `appsettings.json` MinimumLevel overrides ‚úÖ
- [x] Export funkce (CSV/Excel) ‚Äì CSV export implementov√°n v Session 10 (`GET /api/listings/export.csv`, UTF-8 BOM, semicolony) ‚úÖ
- [ ] AI ≈°ablony ‚Äì √∫prava sekc√≠ dle u≈æivatelsk√©ho feedbacku z re√°ln√Ωch anal√Ωz

---

## Debugging Tips

### Common Issues

**Problem:** API container crashes with `Failed to connect to 127.0.0.1:5432`  
**Solution:** `Program.cs` sestavuje connection string z `DB_HOST` (default `localhost`). Docker-compose MUS√ç nastavovat `DB_HOST=postgres` (ne `ConnectionStrings__RealEstate`). Zkontroluj sekci `environment:` v `docker-compose.yml`.

**Problem:** Fotky se nezobrazuj√≠ v Blazor App  
**Solution:** Zkontroluj `ListingService.cs` ‚Äì `StoredUrl = p.StoredUrl` (nikoliv `?? string.Empty`). Pr√°zdn√Ω string `""` se v Blazor `photo.StoredUrl ?? photo.OriginalUrl` nezobraz√≠ jako fallback.

**Problem:** Sources filter (chipy) ‚Äì NullReferenceException p≈ôi odznaƒçen√≠  
**Solution:** `_selectedSourceCodes` mus√≠ b√Ωt `IReadOnlyCollection<string>?` (nullable). MudBlazor 9 `MudChipSet @bind-SelectedValues` m≈Ø≈æe nastavit `null`. Pou≈æij `_selectedSourceCodes?.Count ?? 0`.

**Problem:** API returns 401 when calling `/api/scraping/trigger`  
**Solution:** Scraping endpointy jsou chr√°nƒõny API kl√≠ƒçem. P≈ôidej header `X-Api-Key: dev-key-change-me` (nebo nastav env `API_KEY`).

**Problem:** API returns 500 when calling `/api/scraping/trigger`  
**Solution:** Python scraper nebƒõ≈æ√≠. Spus≈•: `cd scraper && .venv/bin/python run_api.py`  
(Pokud `python` nen√≠ v PATH, mus√≠≈° pou≈æ√≠t virtualenv venv)

**Problem:** EF Core mapping errors (snake_case vs PascalCase)  
**Solution:** Ensure `UseSnakeCaseNamingConvention()` is called in DbContext

**Problem:** MudBlazor compilation errors about type inference  
**Solution:** Add explicit type parameters: `<MudChip T="string">`, `<MudCarousel TData="object">`

**Problem:** Scraper can't connect to database  
**Solution:** Zkontroluj `scraper/config/settings.yaml` ‚Äì host=localhost (local) nebo host=postgres (Docker)

**Problem:** Filter vrac√≠ ≈°patn√° data i po rebuildu Docker image ‚Äî `docker logs` neukazuje ≈æ√°dn√© search SQL  
**Solution:** `lsof -i :5001 -P -n` ‚Äî pokud tam je lok√°lnƒõ bƒõ≈æ√≠c√≠ `RealEstate.Api` proces, `kill <PID>`. Lok√°ln√≠ dotnet proces m√° prioritu p≈ôed Colima/Docker SSH port forwardingem. Curl pak jde na star√Ω lok√°ln√≠ binary m√≠sto na Docker kontejner.

**Problem:** EF Core filtry (PropertyType/OfferType) vracej√≠ 0 v√Ωsledk≈Ø  
**Solution:** Zkontroluj HasConversion v RealEstateDbContext.cs ‚Äì z√°pis mus√≠ b√Ωt `v.ToString()` ("House"), NE ƒçesk√© hodnoty ("D≈Øm"). DB ukl√°d√° v≈ædy anglicky.

**Problem:** EF Core CS8198 ‚Äì `out` parameter in expression tree  
**Solution:** Nepou≈æ√≠vej `Enum.TryParse(v, out var x)` v HasConversion lambda. Pou≈æij switch expression.

**Problem:** Navigation doesn't work in Blazor  
**Solution:** Ensure `@inject NavigationManager Navigation` is present

**Problem:** HTTP vol√°n√≠ v Blazor pokraƒçuj√≠ i po opu≈°tƒõn√≠ str√°nky  
**Solution:** `Listings.razor` implementuje `IDisposable` + `CancellationTokenSource _cts`. Ka≈æd√© HTTP vol√°n√≠ dostane `_cts.Token`, `Dispose()` vol√° `_cts.Cancel()`. Nov√© str√°nky mus√≠ tento pattern kop√≠rovat.

**Problem:** Fulltext hled√°n√≠ je pomal√© (ILIKE full scan)  
**Solution:** Vyu≈æ√≠v√°me `search_tsv` GIN index p≈ôes `EF.Functions.PlainToTsQuery`. Shadow property `SearchTsv` (NpgsqlTsVector) mus√≠ b√Ωt nakonfigurov√°na v `RealEstateDbContext.OnModelCreating`. Nutn√Ω `Npgsql.EntityFrameworkCore.PostgreSQL` v Api.csproj.

**Problem:** UI nereflektuje zmƒõny v C# k√≥du i kdy≈æ byl k√≥d opraven (filtry, ≈ôazen√≠, UI pohled)  
**Solution:** Docker app/api image je star√Ω. **V≈ædy** po zmƒõnƒõ C# k√≥du: `docker compose build --no-cache app api && docker compose up -d --no-deps app api`. Zapomƒõnut√Ω rebuild = star√Ω k√≥d v kontejnerech.

**Problem:** Po restartu Macu / Colimy kontejnery nenabƒõhnou (postgres Exited, scraper ConnectionRefused)  
**Solution:** Zkontroluj `restart: unless-stopped` u v≈°ech 4 slu≈æeb v `docker-compose.yml`. Pokud chyb√≠: `docker update --restart=unless-stopped realestate-db realestate-api realestate-app realestate-scraper`

**Problem:** SReality dra≈æba odkaz vrac√≠ 404  
**Solution:** Dra≈æba skonƒçila ‚Äì SReality ihned ma≈æe inzer√°t. URL form√°t je spr√°vn√Ω (cat_type=3 ‚Üí `/drazba/`), jde o expected chov√°n√≠. Inzer√°t bude deaktivov√°n p≈ôi p≈ô√≠≈°t√≠m `full_rescan`.

**Problem:** MSBuild error `CS2021: File name '**/*.cs'` p≈ôi `docker compose build`  
**Solution:** SDK 10.0 glob cache bug na Colima (overlay2 fs). `Pgvector.EntityFrameworkCore` nebo `Microsoft.NET.Sdk.Web` emituje liter√°ln√≠ glob do CSC m√≠sto expanded file listu. Fix: p≈ôidat do ka≈æd√©ho posti≈æen√©ho `.csproj`:
```xml
<EnableDefaultCompileItems>false</EnableDefaultCompileItems>
<!-- nebo pro Web SDK projekt: -->
<EnableDefaultItems>false</EnableDefaultItems>
```
A explicitnƒõ vyjmenovat `<Compile Include="Subdir/*.cs" />` bez `**` rekurze. Hotovo v `Infrastructure.csproj`, `Api.csproj`, `Background.csproj`.

**Problem:** Po zmƒõnƒõ C# k√≥du je nutn√© pou≈æ√≠t `--no-cache`  
**Solution:** Pou≈æij `docker compose build --no-cache app api` (bez cache).

**Problem:** AI instrukce ≈°ablona se nezmƒõnila i po editaci `.md` souboru v kontejneru  
**Solution:** Soubory v `/app/Templates/` jsou souƒç√°st√≠ image ‚Äì `docker cp` funguje jen do restartu. Trval√° zmƒõna: `docker compose build --no-cache api && docker compose up -d --no-deps api`.

**Problem:** Python scraper vol√° `db_manager.get_connection()` ‚Üí `AttributeError`  
**Solution:** DatabaseManager nem√° metodu `get_connection()`. Spr√°vn√Ω pattern: `async with db_manager.acquire() as conn:`. Pro READ a WRITE operace v jedn√© funkci pou≈æij dvƒõ oddƒõlen√© `acquire()` vol√°n√≠.

**Problem:** `CREATE TRIGGER` sel≈æe s `function update_updated_at_column() does not exist`  
**Solution:** Funkce je definov√°na v `init-db.sql` (bƒõ≈æ√≠ jen na ƒçist√©m DB). Pro migrace existuj√≠c√≠ DB mus√≠ `migrate_postgis.sql` obsahovat `CREATE OR REPLACE FUNCTION update_updated_at_column()` p≈ôed triggerem.

**Problem:** Postgres Docker image hl√°s√≠ collation version mismatch po p≈ôechodu na ARM64 image  
**Solution:** `docker exec -it realestate-db psql -U postgres -d realestate_dev -c "ALTER DATABASE realestate_dev REFRESH COLLATION VERSION;"`

**Problem:** `platform: linux/arm64/v8` chyb√≠ v docker-compose.yml ‚Äì Rosetta AMD64 emulace  
**Solution:** `postgis/postgis:15-3.4` bez platform spec st√°hne AMD64 variantu a bƒõ≈æ√≠ p≈ôes Rosetta 2. P≈ôidej `platform: linux/arm64/v8` do postgres service v docker-compose.yml + `docker compose pull postgres && docker compose up -d --no-deps postgres`.

---

## Resources

- **Repository:** https://github.com/cybersmurf/RealEstateAggregator
- **Session Summary:** /docs/AI_SESSION_SUMMARY.md
- **Technical Design:** /docs/TECHNICAL_DESIGN.md
- **API Contracts:** /docs/API_CONTRACTS.md
- **Backlog:** /docs/BACKLOG.md
- **Database Schema:** /scripts/init-db.sql
- **PostGIS migrace:** /scripts/migrate_postgis.sql
- **Katastr migrace:** /scripts/migrate_cadastre.sql
- **Loga zdroj≈Ø:** /src/RealEstate.App/wwwroot/images/logos/ (13 soubor≈Ø SVG/PNG)

---

## Copilot-Specific Tips

When generating code:

1. **Always use async/await** for I/O operations (database, HTTP, file)
2. **Include error handling** with try/catch and user-facing messages (Snackbar in Blazor)
3. **Follow existing patterns** from similar files (e.g., remax_scraper.py template for new scrapers)
4. **Add logging** using injected ILogger<T> or Python logging
5. **Use type hints** in Python, records in C#
6. **Check configuration** in appsettings.json before hardcoding URLs
7. **Test with curl** before implementing UI

**Example prompt for Copilot Chat:**
```
Create a new scraper for sreality.cz based on remax_scraper.py.
Use regex selectors for robustness.
Extract: title, price, location, photos (max 20), property type, area.
Include upsert to database via get_db_manager().
```

---

### ‚úÖ Dokonƒçeno v Session 13 (2026-02-26)
- [x] **Serilog structured logging** ‚Äì `Serilog.AspNetCore` 9 + `CompactJsonFormatter` + Enrichers (Environment/Process/Thread); bootstrap logger pro zachycen√≠ chyb p≈ôed DI; `UseSerilog` s `ReadFrom.Configuration` + `ReadFrom.Services`; Development: obarven√ø console output s SourceContext; Production: CompactJsonFormatter (JSON) pro log aggregaci; `UseSerilogRequestLogging()` ‚Äì HTTP metoda, cesta, status, ƒças obsluhy; `appsettings.json` MinimumLevel overrides (EF Core/Microsoft ‚Üí Warning); `try/catch/finally` wrapper s `Log.Fatal` + `Log.CloseAndFlush()`

### ‚úÖ Dokonƒçeno v Session 20 (2026-02-27)
- [x] **ARCHITECTURE.md kompletn√≠ p≈ôepis** ‚Äì 53 205 znak≈Ø, 16 sekc√≠, Mermaid diagramy v≈°ude (Docker Compose architektura, scraping flow, FilterManager, APScheduler, RAG ingestion/retrieval/generation + pln√Ω sekvenƒçn√≠ diagram, KN OCR end-to-end, koridor PostGIS pipeline, geocoding pipeline, robustn√≠ JSON parsov√°n√≠); RAG matematika (cosine similarity vzorec), EPSG:5514 vysvƒõtlen√≠, ERD se v≈°emi tabulkami, indexov√° strategie tabulkou, embedding batch sizes
- [x] **bulk-download `?onlyMyListings=true`** ‚Äì `PhotoDownloadService.DownloadBatchAsync()` + `IPhotoDownloadService` interface + `PhotoEndpoints` roz≈°√≠≈ôeny o filtr `Liked/ToVisit/Visited` p≈ôes `EXISTS` subquery na `user_listing_states`; ≈°et≈ô√≠ disk (nestahuje 15k fotek pro nezaj√≠mav√© inzer√°ty)

### ‚úÖ Dokonƒçeno v Session 23 (2026-02-27)
- [x] **REAS CDN pagination bug** ‚Äì CDN cachuje HTML `?page=N` str√°nky (v≈ædy page 1 = 10 inzer√°t≈Ø); fix: 2. CATEGORIES entry `?sort=newest` ‚Üí ~18‚Äì20 unik√°tn√≠ch inzer√°t≈Ø/run; `full_rescan=True` ‚Üí `_next/data/{buildId}` API (bypass CDN, re√°ln√° paginace), `_get_build_id()`, `_fetch_listing_page_api()` s GPS bbox post-filtrem, `seen_ids` dedup
- [x] **REAS anonymized listingy** ‚Äì skip `isAnonymized/isAnonymous=True` inzer√°t≈Ø (REAS subscription-only, municipality count=0, nelze sesb√≠rat); Kucha≈ôovice REAS `69a188220233fdb43521d123` = z√°mƒõrnƒõ skryt√©
- [x] **Commit** `e01d725` ‚Äì fix(reas): fix CDN pagination + add sort=newest category

### ‚úÖ Dokonƒçeno v Session 25 (2026-02-28)
- [x] **AI coverage anal√Ωza** ‚Äì potvrzeno: 91 % normalize/smart-tags a 79 % price-signal = **100 % zpracovateln√Ωch dat**; zb√Ωvaj√≠c√≠ inzer√°ty z√°mƒõrnƒõ p≈ôeskoƒçeny (popis < 100 znak≈Ø ‚Üí 132 inz., cena NULL ‚Üí 327 inz.)
- [x] **Full rescan v≈°ech 13 scraper≈Ø** ‚Äì zachycen√≠ zame≈°k√°n√Ωch inzer√°t≈Ø po SReality geo filter fixu (commit `91b8157`)
- [x] **AI joby dobƒõhly** ‚Äì 1558 celkem, 1425 smart-tags, 1422 normalize, 1226 price-signal

### ‚úÖ Dokonƒçeno v Session 24 (2026-02-27)
- [x] **SReality geo filtr fix** ‚Äì bug: API vrac√≠ pro mal√© obce `"Ulice, Obec"` bez okresu (napr. `"Ke Kapliƒçce, Kucha≈ôovice"`) ‚Üí geo filtr zahodil listing; fix v `filters.py`: `combined_location` nyn√≠ kombinuje `location_text + district + municipality + region`; fix v `sreality_scraper.py`: `DISTRICT_ID_TO_NAME` mapping + `_normalize_list_item` napln√≠ `district='Znojmo'` pro `locality_district_id=77`
- [x] **Listing 2031444812** (Ke Kapliƒçce, Kucha≈ôovice, 4,39M) ihned sesb√≠r√°n po fixu; full_rescan SREALITY pro doƒçerp√°n√≠ dal≈°√≠ch zame≈°k√°n√Ωch inzer√°t≈Ø
- [x] **Commit** `91b8157` ‚Äì fix(sreality): geo filter miss pro obce bez okresu v location_text

**Last Updated:** 28. √∫nora 2026 (Session 25)
**Current Commit:** `e82f8a6` ‚Äì docs: session 23+24 summary
**DB stav:** 1558 inzer√°t≈Ø, 13 zdroj≈Ø, GPS: 97 % pokryt√≠, AI: normalize 91 %, smart-tags 91 %, price-signal 79 % (= 100 % zpracovateln√Ωch dat)
**Docker stack:** plnƒõ funkƒçn√≠, Blazor App :5002, API :5001, Scraper :8001, Postgres :5432 (PostGIS 3.4 + pgvector ARM64 nativn√≠), **MCP Server (Claude Desktop integration)**
**Unit testy:** 141 C# zelen√Ωch + 83 Python zelen√Ωch

### ‚úÖ Dokonƒçeno v Session 14 (2026-02-26)
- [x] **MCP Tools vylep≈°en√≠** ‚Äì `get_listing` docstring: zd≈Ørazn√≠ workflow (1. load data, 2. read analyses, 3. save new); kompletn√≠ popis v≈°ech pol√≠ (Z√ÅPIS Z PROHL√çDKY, Drive URL, fotky); `get_analyses` docstring: zd≈Ørazn√≠ ≈æe vrac√≠ V≈†ECHNY anal√Ωzy v historii (pln√Ω obsah bez zkr√°cen√≠); `save_analysis` docstring: workflow ulo≈æen√≠ + auto `source="claude"`; zv√Ω≈°en upload limit na 150 fotek (Kestrel 1GB, FormOptions 1GB, MudFileUpload MaximumFileCount=150); local inspection photo storage + API endpoint `GET /api/listings/{id}/inspection-photos`; `ListingDetailDto`: p≈ôid√°ny `DriveFolderUrl`, `DriveInspectionFolderUrl`, `HasOneDriveExport`; Google Drive MCP credentials setup (`~/.gdrive-server-credentials.json`)

### ‚úÖ Dokonƒçeno v Session 12 (2026-02-26)
- [x] **Moje inzer√°ty str√°nka** ‚Äì `MyListingsSummaryDto` + `UserListingsGroupDto`; `IListingService.GetMyListingsAsync()` + implementace; `GET /api/listings/my-listings` (inzer√°ty = status ‚â† New, seskupen√© dle stavu, po≈ôad√≠ ToVisit‚ÜíLiked‚ÜíVisited‚ÜíDisliked); `MyListings.razor` (barevn√© sekce, souhrn√© ƒçipy, pr√°zdn√Ω stav, ikona pozn√°mek, CancellationToken); NavMenu odkaz "Moje inzer√°ty"; 141/141 test≈Ø zelen√Ωch
