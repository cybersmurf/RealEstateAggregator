# RealEstate Scraper - Python FastAPI

Python FastAPI aplikace pro scraping realitn√≠ch inzer√°t≈Ø z ƒçesk√Ωch realitn√≠ch port√°l≈Ø.

## üöÄ Quick Start

### 1. Instalace dependencies

```bash
cd scraper

# Vytvo≈ôit virtual environment
python -m venv venv
source venv/bin/activate  # Mac/Linux
# venv\Scripts\activate  # Windows

# Instalovat bal√≠ƒçky
pip install -r requirements.txt

# Pokud pou≈æ√≠v√°≈° Playwright (pro JS-heavy weby)
playwright install
```

### 2. Spu≈°tƒõn√≠ FastAPI serveru

```bash
# Spustit API server na portu 8001
python run_api.py

# Nebo pomoc√≠ uvicorn p≈ô√≠mo
uvicorn api.main:app --host 0.0.0.0 --port 8001 --reload
```

Server pobƒõ≈æ√≠ na: **http://localhost:8001**

### 3. Swagger dokumentace

Otev≈ôi prohl√≠≈æeƒç: **http://localhost:8001/docs**

## üì° API Endpoints

### `POST /v1/scrape/run`

Spust√≠ scraping job v pozad√≠.

**Request body:**
```json
{
  "source_codes": ["REMAX", "MMR", "PRODEJMETO", "ZNOJMOREALITY", "SREALITY", "NEMZNOJMO", "HVREALITY"],
  "full_rescan": false
}
```

**Response:**
```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "Queued",
  "message": "Scraping job enqueued."
}
```

### `GET /v1/scrape/jobs/{job_id}`

Z√≠sk√° status konkr√©tn√≠ho jobu.

**Response:**
```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "source_codes": ["REMAX"],
  "full_rescan": false,
  "created_at": "2026-02-22T10:30:00",
  "status": "Succeeded",
  "error_message": null
}
```

### `GET /v1/scrape/jobs`

Vr√°t√≠ seznam v≈°ech job≈Ø.

## üîß Architektura

```
scraper/
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ main.py          # FastAPI aplikace, endpointy
‚îÇ   ‚îî‚îÄ‚îÄ schemas.py       # Pydantic modely (DTOs)
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ runner.py        # Job orchestrator
‚îÇ   ‚îî‚îÄ‚îÄ scrapers/
‚îÇ       ‚îú‚îÄ‚îÄ remax_scraper.py
‚îÇ       ‚îú‚îÄ‚îÄ mmreality_scraper.py
‚îÇ       ‚îú‚îÄ‚îÄ prodejmeto_scraper.py
‚îÇ       ‚îú‚îÄ‚îÄ sreality_scraper.py
‚îÇ       ‚îî‚îÄ‚îÄ znojmoreality_scraper.py
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ settings.yaml    # Konfigurace
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ run_api.py          # Startup script
```

## üîå Integrace s .NET API

.NET API vol√° Python API pomoc√≠ HttpClient:

```csharp
// .NET endpoint
POST /api/scraping/trigger
  ‚Üì
HttpClient POST http://localhost:8001/v1/scrape/run
  ‚Üì
Python FastAPI spust√≠ background job
  ‚Üì
Job runner zavol√° scrapers (Remax, MMR, Prodejme.to, Znojmo Reality, Sreality)
```

## üìù Implementace scraper≈Ø

Ka≈æd√Ω scraper implementuje `run()` metodu:

```python
class RemaxScraper:
    async def run(self, full_rescan: bool = False) -> int:
        # 1. Fetch list str√°nky
        # 2. Parse inzer√°ty
        # 3. Fetch detail str√°nek
        # 4. Normalizuj data
        # 5. Ulo≈æ do DB
        return scraped_count
```

### TODO pro production ready scrapers:

- [ ] Str√°nkov√°n√≠ (iterovat p≈ôes v≈°echny str√°nky, kde to d√°v√° smysl)
- [ ] Error handling a retry logika
- [ ] Rate limiting (respektovat servery)
- [ ] Logging do structured logs
- [ ] Detekce zmƒõn (scrapovat jen nov√©/updatnut√©)
- [ ] Photo download a storage
- [ ] Proxy support (pokud je pot≈ôeba)

## üß™ Testov√°n√≠

```bash
# Spustit API
python run_api.py

# V jin√©m termin√°lu - test endpointu
curl -X POST http://localhost:8001/v1/scrape/run \
  -H "Content-Type: application/json" \
  -d '{"source_codes": ["REMAX"], "full_rescan": false}'

# Sledovat status jobu
curl http://localhost:8001/v1/scrape/jobs/{job_id}
```

## üê≥ Docker

V `docker-compose.yml` u≈æ m√°≈° p≈ôipraven√Ω service:

```yaml
scraper:
  build: ./scraper
  ports:
    - "8001:8001"
  environment:
    - DATABASE_URL=postgresql://postgres:dev@postgres:5432/realestate_dev
```

## üìö Dal≈°√≠ kroky

1. **DB integrace**: Napoj scrapers na PostgreSQL pomoc√≠ asyncpg
2. **Scheduling**: APScheduler pro automatick√© spou≈°tƒõn√≠ (nap≈ô. ka≈æd√Ωch 12 hodin)
3. **Monitoring**: Logov√°n√≠ do structured logs, metriky
4. **Proxy pooling**: Pokud weby blokuj√≠, p≈ôidat proxy rotaci
5. **Redis queue**: M√≠sto in-memory dictionary pou≈æ√≠t Redis pro joby

---

**Happy scraping!** üè†‚ú®
